{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Feng\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from joblib import load\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier # used with Linear SVC\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# from multilabel import *\n",
    "\n",
    "from text_cleaning_functions import text_cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "\n",
    "# del_punct = string.punctuation\n",
    "# del_punct = del_punct.replace(\"-\", \"\")  # don't remove hyphens\n",
    "# rm_pattern = r\"[{}]\".format(del_punct)\n",
    "\n",
    "# def clean_text(text):\n",
    "#     text = text.lower()  # convert to all lower case\n",
    "#     text = re.sub(r\"what's\", \"what is \", text)\n",
    "#     text = re.sub(r\"\\'s\", \" \", text)\n",
    "#     text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "#     text = re.sub(r\"can't\", \"can not \", text)\n",
    "#     text = re.sub(r\"n't\", \" not \", text)\n",
    "#     text = re.sub(r\"i'm\", \"i am \", text)\n",
    "#     text = re.sub(r\"\\'re\", \" are \", text)\n",
    "#     text = re.sub(r\"\\'d\", \" would \", text)\n",
    "#     text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "#     text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "#     text = re.sub(rm_pattern, \"\", text)  # remove punctuations\n",
    "#     text = re.sub(r'[0-9]', ' ', text)  # remove digits 0-9\n",
    "#     text = re.sub('\\W', ' ', text)   # removes non-word character\n",
    "#     text = re.sub('\\s+', ' ', text)  # removes extra spaces\n",
    "#     text = text.strip(' ')\n",
    "#     return text\n",
    "# from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# from nltk.corpus import stopwords\n",
    "# import string\n",
    "\n",
    "# # Define stopwords to exclude\n",
    "# stop = set(stopwords.words('english'))\n",
    "# stop.update((\"to\",\"cc\",\"subject\",\"http\",\"from\",\"sent\", \"ect\", \"u\", \"fwd\", \"www\", \"com\"))\n",
    "\n",
    "# # Define punctuations to exclude and lemmatizer\n",
    "# exclude = set(string.punctuation)\n",
    "\n",
    "# # df_processed_text = pd.read_csv('processed_text.csv', usecols = ['cleaned_text'])\n",
    "\n",
    "# wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# def text_lemmatizer(text):     \n",
    "#     tokens = word_tokenize(text)\n",
    "#     lemmatized_text = []\n",
    "    \n",
    "#     for token in tokens:\n",
    "#         # lemmatized = wordnet_lemmatizer.lemmatize(token, pos='v')\n",
    "#         lemmatized_text.append(wordnet_lemmatizer.lemmatize(token, pos='v'))\n",
    "#         lemmatized_text.append(' ')\n",
    "        \n",
    "#     return ''.join(lemmatized_text)\n",
    "\n",
    "\n",
    "# # text_cleaner includes text_lemmatizer function\n",
    "# def text_cleaner(text, stop):\n",
    "#     text = clean_text(text)\n",
    "#     stop_free = \" \".join([i for i in text.lower().split() if((i not in stop) and (not i.isdigit()))])\n",
    "#     punc_free = ''.join(i for i in stop_free if i not in exclude)\n",
    "#     normalized = \" \".join(wordnet_lemmatizer.lemmatize(i) for i in punc_free.split())  \n",
    "    \n",
    "#     return normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_text) == len(train_labels)\n",
    "dataset_directory = \"C:/Users/Feng/Coding projects/toxic-comments-datasets/\"\n",
    "train_df = pd.read_csv(dataset_directory + \"train.csv.zip\", usecols = ['comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'])\n",
    "train_df = train_df.astype({'toxic':'int16',\n",
    "                            'severe_toxic':'int16',\n",
    "                            'obscene':'int16',\n",
    "                            'threat':'int16',\n",
    "                            'insult':'int16',\n",
    "                            'identity_hate':'int16'})\n",
    "\n",
    "train_df = train_df.dropna()  # I found 5 nan rows in cleaned_text, so I just drop those rows altogether\n",
    "# print(train_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 29.2 s\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df['cleaner_text'] = train_df['comment_text'].map(lambda comments : text_cleaner(comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159096    filthy stinking crow back dirty crow better de...\n",
       "159099          fucking pathetic moron jimbo wale rootmyass\n",
       "159281           lol gay never know good feel fuck woman as\n",
       "159312    walter mercado antonio quite frankly fucker co...\n",
       "159400    shalom semite get fuck kill son bitch leave wi...\n",
       "Name: cleaner_text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(train_df.info())\n",
    "display(train_df[train_df.severe_toxic==1]['cleaner_text'].tail())\n",
    "# print(train_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    explanation edits made username hardcore metal...\n",
      "1    daww match background colour seemingly stuck t...\n",
      "2    hey man really trying edit war guy constantly ...\n",
      "3    make real suggestion improvement wondered sect...\n",
      "4                        sir hero chance remember page\n",
      "Name: cleaner_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_df['cleaner_text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "train_text = train_df['cleaner_text']\n",
    "train_labels = train_df[LABELS]\n",
    "\n",
    "# X_train_m, X_test_m, y_train_m, y_test_M = multilabel_train_test_split(train_text, train_labels, size=0.25)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_text, train_labels, test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline combining a text feature extractor with multi lable classifier\n",
    "countvec_NB_pipeline = Pipeline([\n",
    "                ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "                ('clf', MultinomialNB()) ])\n",
    "\n",
    "tfidf_NB_pipeline = Pipeline([\n",
    "                ('vectorizer', TfidfVectorizer(stop_words='english')),\n",
    "                ('clf', MultinomialNB()) ])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision vs Recall\n",
    "\n",
    "Precision = TP/(TP+FP)\n",
    "\n",
    "Recall = TP/(TP+FN)\n",
    "\n",
    "FP = good comments wrongfully labeled toxic\n",
    "\n",
    "FN = undetected toxic comments\n",
    "\n",
    "Having high accuracy is misleading, since positive toxic labels are sparse. The question is, do I want high precision or high recall. Precision is a measure of true positives (correctly labeled toxic comments) relative to false positives (clean comments wrongfully labeled toxic). Recall measures true positives relative to false negatives (toxic comments that were not detected). In other words, do I want to minimize wrongfully labeled clean comments or undetected toxic comments. In my opinion, the former is preferred, since randomly deleting clean comments will upset users. Therefore, high precision is more preferred than high recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_countvec = CountVectorizer().fit_transform(train_text)\n",
    "train_text_tfidfvec = TfidfVectorizer().fit_transform(train_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVec + NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1']\n"
     ]
    }
   ],
   "source": [
    "scores_dict = {}\n",
    "print(['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1'])\n",
    "\n",
    "def vectorizer_test_pipeline(vectorized_text, clf):\n",
    "    '''\n",
    "    vectorized_text: sparse matrix of comments from CountVectorizer of TfidfVectorizer\n",
    "    clf: a classifier for supervised learning\n",
    "    '''\n",
    "    \n",
    "    X_train_vec, X_test_vec, y_train, y_test = train_test_split(vectorized_text, train_labels, test_size=0.25)\n",
    "    \n",
    "    for label in LABELS:\n",
    "        print('... Processing {}'.format(label))\n",
    "        \n",
    "        clf.fit(X_train_vec, y_train[label])\n",
    "\n",
    "        pred = clf.predict(X_test_vec)\n",
    "        test = y_test[label]\n",
    "        \n",
    "        scores = [accuracy_score(test, pred), balanced_accuracy_score(test,pred), precision_score(test, pred), recall_score(test, pred), f1_score(test, pred) ] \n",
    "        scores_dict[label] = scores\n",
    "        # scores = np.round(scores, decimals = 2)\n",
    "        \n",
    "        print(np.round(scores, decimals = 2))\n",
    "\n",
    "    pred_scores = pd.DataFrame(scores_dict, index=['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1'])\n",
    "    display(np.round(pred_scores.T, decimals=2))\n",
    "    \n",
    "    return(pred_scores.T)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96 0.83 0.85 0.67 0.75]\n",
      "... Processing severe_toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99 0.62 0.52 0.25 0.34]\n",
      "... Processing obscene\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98 0.84 0.85 0.69 0.76]\n",
      "... Processing threat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.   0.6  0.31 0.21 0.25]\n",
      "... Processing insult\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97 0.75 0.75 0.52 0.61]\n",
      "... Processing identity_hate\n",
      "[0.99 0.6  0.49 0.2  0.28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe_toxic</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obscene</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threat</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insult</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identity_hate</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  balanced_accuracy  precision  recall    f1\n",
       "toxic              0.96               0.83       0.85    0.67  0.75\n",
       "severe_toxic       0.99               0.62       0.52    0.25  0.34\n",
       "obscene            0.98               0.84       0.85    0.69  0.76\n",
       "threat             1.00               0.60       0.31    0.21  0.25\n",
       "insult             0.97               0.75       0.75    0.52  0.61\n",
       "identity_hate      0.99               0.60       0.49    0.20  0.28"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_vec_scores = vectorizer_test_pipeline(train_text_countvec, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing toxic\n",
      "[0.96 0.8  0.93 0.6  0.73]\n",
      "... Processing severe_toxic\n",
      "[0.99 0.61 0.57 0.22 0.32]\n",
      "... Processing obscene\n",
      "[0.98 0.81 0.91 0.62 0.73]\n",
      "... Processing threat\n",
      "[1.   0.55 0.73 0.09 0.17]\n",
      "... Processing insult\n",
      "[0.97 0.75 0.81 0.5  0.62]\n",
      "... Processing identity_hate\n",
      "[0.99 0.57 0.64 0.14 0.23]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe_toxic</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obscene</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threat</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insult</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identity_hate</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  balanced_accuracy  precision  recall    f1\n",
       "toxic              0.96               0.80       0.93    0.60  0.73\n",
       "severe_toxic       0.99               0.61       0.57    0.22  0.32\n",
       "obscene            0.98               0.81       0.91    0.62  0.73\n",
       "threat             1.00               0.55       0.73    0.09  0.17\n",
       "insult             0.97               0.75       0.81    0.50  0.62\n",
       "identity_hate      0.99               0.57       0.64    0.14  0.23"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfidf_vec_scores = vectorizer_test_pipeline(train_text_tfidfvec, LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Tfidf to BoW\n",
    "Based on metrics of recall and f1, **BoW** is the clear winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 198129)\n",
      "(159571, 198129)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy             0.98\n",
       "balanced_accuracy    0.71\n",
       "precision            0.63\n",
       "recall               0.42\n",
       "f1                   0.50\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "accuracy             0.98\n",
       "balanced_accuracy    0.68\n",
       "precision            0.76\n",
       "recall               0.36\n",
       "f1                   0.47\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_text_countvec.shape)\n",
    "print(train_text_tfidfvec.shape)\n",
    "display(round(count_vec_scores.mean(),2))\n",
    "display(round(tfidf_vec_scores.mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1']\n",
      "... Processing toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9 0.5 0.  0.  0. ]\n",
      "... Processing severe_toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99 0.5  0.   0.   0.  ]\n",
      "... Processing obscene\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95 0.5  0.   0.   0.  ]\n",
      "... Processing threat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  0.5 0.  0.  0. ]\n",
      "... Processing insult\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95 0.5  0.   0.   0.  ]\n",
      "... Processing identity_hate\n",
      "[0.99 0.5  0.   0.   0.  ]\n",
      "               accuracy  balanced_accuracy  precision  recall   f1\n",
      "toxic              0.90                0.5        0.0     0.0  0.0\n",
      "severe_toxic       0.99                0.5        0.0     0.0  0.0\n",
      "obscene            0.95                0.5        0.0     0.0  0.0\n",
      "threat             1.00                0.5        0.0     0.0  0.0\n",
      "insult             0.95                0.5        0.0     0.0  0.0\n",
      "identity_hate      0.99                0.5        0.0     0.0  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# scores_dict = {}\n",
    "# print(['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1'])\n",
    "# X_train_vec = TfidfVectorizer().fit_transform(X_train)\n",
    "# X_test_vec = TfidfVectorizer().fit_transform(X_test)\n",
    "# clf = MultinomialNB()\n",
    "# for label in LABELS:\n",
    "#     print('... Processing {}'.format(label))\n",
    "#     clf.fit(X_train_vec, y_train[label])\n",
    "#     # countvec_NB_pipeline.fit(X_train.iloc[0:10000], y_train[label].iloc[0:10000]) # train with a slice \n",
    "#     # tfidf_NB_pipeline.fit(X_train, y_train[label])  # train with whole dataset\n",
    "\n",
    "#     # compute the testing accuracy\n",
    "#     # pred = tfidf_NB_pipeline.predict(X_test)\n",
    "#     pred = clf.predict(X_test_vec)\n",
    "#     test = y_test[label]\n",
    "    \n",
    "#     scores = [accuracy_score(test, pred), balanced_accuracy_score(test, pred), precision_score(test, pred), recall_score(test, pred), f1_score(test, pred) ] \n",
    "#     scores_dict[label] = scores\n",
    "    \n",
    "#     print(np.round(scores, decimals = 2))\n",
    "\n",
    "# scores_tfidf_NB = pd.DataFrame(scores_dict, index=['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1']).T\n",
    "# print(np.round(scores_tfidf_NB, decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------CountVectorizer scores----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe_toxic</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obscene</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threat</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insult</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identity_hate</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  balanced_accuracy  precision  recall    f1\n",
       "toxic              0.91               0.52       0.71    0.04  0.07\n",
       "severe_toxic       0.99               0.57       0.26    0.14  0.18\n",
       "obscene            0.95               0.53       0.61    0.06  0.11\n",
       "threat             0.99               0.54       0.05    0.09  0.07\n",
       "insult             0.95               0.53       0.58    0.06  0.11\n",
       "identity_hate      0.99               0.60       0.36    0.20  0.26"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- CountVectorizer mean scores --\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy             0.963\n",
       "balanced_accuracy    0.549\n",
       "precision            0.430\n",
       "recall               0.100\n",
       "f1                   0.135\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------TfidfVectorizer scores----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe_toxic</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obscene</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threat</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insult</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identity_hate</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  balanced_accuracy  precision  recall   f1\n",
       "toxic              0.90                0.5        0.0     0.0  0.0\n",
       "severe_toxic       0.99                0.5        0.0     0.0  0.0\n",
       "obscene            0.95                0.5        0.0     0.0  0.0\n",
       "threat             1.00                0.5        0.0     0.0  0.0\n",
       "insult             0.95                0.5        0.0     0.0  0.0\n",
       "identity_hate      0.99                0.5        0.0     0.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- TfidfVectorizer mean scores --\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy             0.964\n",
       "balanced_accuracy    0.500\n",
       "precision            0.000\n",
       "recall               0.000\n",
       "f1                   0.000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scores_count_NB = pred_scores.T\n",
    "# print('--------CountVectorizer scores----------')\n",
    "# display(np.round(scores_count_NB, 2))\n",
    "# print('-- CountVectorizer mean scores --')\n",
    "# display(np.round(scores_count_NB.mean(), 3))\n",
    "# print('--------TfidfVectorizer scores----------')\n",
    "# display(np.round(scores_tfidf_NB, 2))\n",
    "# print('-- TfidfVectorizer mean scores --')\n",
    "# display(np.round(scores_tfidf_NB.mean(), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(stop_words='english')),\n",
       "                ('clf', OneVsRestClassifier(estimator=MultinomialNB()))])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a pipeline combining a text feature extractor with multi lable classifier\n",
    "OVR_NB_pipeline = Pipeline([\n",
    "                # ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None))),\n",
    "            ])\n",
    "\n",
    "OVR_NB_pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OVR_NB_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[39m=\u001b[39m OVR_NB_pipeline\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      2\u001b[0m y_proba \u001b[39m=\u001b[39m OVR_NB_pipeline\u001b[39m.\u001b[39mpredict_proba(X_test)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(LABELS)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'OVR_NB_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = OVR_NB_pipeline.predict(X_test)\n",
    "y_proba = OVR_NB_pipeline.predict_proba(X_test)\n",
    "\n",
    "print(LABELS)\n",
    "multi_cm = multilabel_confusion_matrix(y_test, y_pred, samplewise=False)\n",
    "\n",
    "for i in range(multi_cm.shape[0]):\n",
    "    #[[TN, FP],\n",
    "    # [FN, TP]]\n",
    "    print(LABELS[i])\n",
    "    print(multi_cm[i,:,:])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_table(test, pred, proba):\n",
    "    \n",
    "    hamming_losses = []\n",
    "    acc_scores = []\n",
    "    bal_acc_scores = []\n",
    "    roc_auc_scores = []\n",
    "    scores_multi = {}\n",
    "\n",
    "    for i, label in enumerate(LABELS):\n",
    "        \n",
    "        acc = accuracy_score(test[:,i], pred[:,i])\n",
    "        acc_scores.append(acc)\n",
    "        \n",
    "        bal_acc = balanced_accuracy_score(test[:,i], pred[:,i])\n",
    "        bal_acc_scores.append(bal_acc)\n",
    "        \n",
    "        # hamming = hamming_loss(test[:,i], pred[:,i])\n",
    "        # hamming_losses.append(hamming)\n",
    "\n",
    "        roc_auc = roc_auc_score(test[:,i], proba[:,i])\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        \n",
    "    scores_multi['accuracy']= acc_scores\n",
    "    scores_multi['balanced_accuracy']= bal_acc_scores\n",
    "    scores_multi['roc_auc_score'] = roc_auc_scores\n",
    "    # scores_multi['hamming_loss']= hamming_losses  # hamming_loss isn't that useful\n",
    "    \n",
    "    scores_multi['precision'] = precision_score(test, pred, average=None) \n",
    "    scores_multi['recall'] = recall_score(test, pred, average=None) \n",
    "    scores_multi['f1'] = f1_score(test, pred, average=None) \n",
    "\n",
    "    scores_multi_df = pd.DataFrame(scores_multi, index = LABELS)\n",
    "    print(np.round(scores_multi_df,3))\n",
    "    \n",
    "    return scores_multi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m test \u001b[39m=\u001b[39m y_test\u001b[39m.\u001b[39mvalues  \u001b[39m# y_test is a DataFrame, so it must be converted into nd.array\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m pred \u001b[39m=\u001b[39m y_pred  \u001b[39m# binary predictions for each label\u001b[39;00m\n\u001b[0;32m      3\u001b[0m proba \u001b[39m=\u001b[39m y_proba \u001b[39m# probabilities for each prediction\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmetrics_table\u001b[39m(test, pred, proba):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "test = y_test.values  # y_test is a DataFrame, so it must be converted into nd.array\n",
    "pred = y_pred  # binary predictions for each label\n",
    "proba = y_proba # probabilities for each prediction\n",
    "\n",
    "scores_multi_df = metrics_table(test, pred, proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
    "\n",
    "param_grid = {'alpha': np.arange(0.0001, 1, 5)}\n",
    "\n",
    "# Define a pipeline combining a text feature extractor with multi lable classifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_text, train_labels, test_size=0.25)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
      "0      0             0        0       0       0                0.898432\n",
      "1      0             0        0       0       0                0.035380\n",
      "                     1        0       1       0                0.023639\n",
      "                                      0       0                0.011130\n",
      "                     0        0       1       0                0.007621\n",
      "dtype: float64\n",
      "toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
      "0      0             0        0       0       0                0.897972\n",
      "1      0             0        0       0       0                0.035898\n",
      "                     1        0       1       0                0.024341\n",
      "                                      0       0                0.010679\n",
      "                     0        0       1       0                0.007596\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts(normalize=True).head())\n",
    "print(y_test.value_counts(normalize=True).head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   24.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_scores: [0.665596   0.6533872  0.65558413 0.65649536 0.65011609]\n",
      "average f1_score: 0.6562357575288501\n",
      "alpha: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   25.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_scores: [0.67091256 0.65440686 0.65723065 0.66116602 0.65353902]\n",
      "average f1_score: 0.6594510233374304\n",
      "alpha: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   24.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_scores: [0.67183606 0.65665278 0.65904582 0.66457622 0.65618933]\n",
      "average f1_score: 0.6616600416763341\n",
      "alpha: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   23.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_scores: [0.6722973  0.65754503 0.65955197 0.66585389 0.65570382]\n",
      "average f1_score: 0.6621903999521076\n",
      "alpha: 0.3\n",
      "f1_scores: [0.67264916 0.6580052  0.65982806 0.66590389 0.65800287]\n",
      "average f1_score: 0.6628778352506939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   24.7s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for alpha_index in np.array([0.1, 0.15, 0.2, 0.25, 0.3]):\n",
    "    \n",
    "    print('-- alpha: {} --'.format(alpha_index))\n",
    "    OVR_NB_pipeline = Pipeline([\n",
    "                    # ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                    ('Vectorizer', CountVectorizer(stop_words='english')),\n",
    "                    ('MultiNB', OneVsRestClassifier(MultinomialNB(alpha=alpha_index) )),\n",
    "                ])\n",
    "\n",
    "    cv = cross_val_score(OVR_NB_pipeline, X_train, y_train, cv=kf, scoring ='f1_micro', verbose=0)\n",
    "    print('f1_scores: {}'.format(cv))\n",
    "    print('average f1_score: {}'.format(np.mean(cv)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha_f1_macro = {'alpha': [0.0001, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 1.2], \n",
    "                'f1_macro': [0.463, 0.515, 0.511, 0.505, 0.497, 0.493, 0.481, 0.474, 0.462, 0.455, 0.447, 0.419]}\n",
    "alpha_f1_micro = {'alpha': [0.0001, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.6], \n",
    "                'f1_micro': [0.600, 0.656, 0.659, 0.662, 0.662, 0.663, 0.659, 0.650]}\n",
    "\n",
    "plt.plot(alpha_f1_macro['alpha'], alpha_f1_macro['f1_macro'], label='f1_macro')\n",
    "plt.plot(alpha_f1_micro['alpha'], alpha_f1_micro['f1_micro'], label='f1_micro')\n",
    "\n",
    "plt.xlabel('alpha parameter')\n",
    "plt.ylabel('f1_scores')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = 0.1\n",
    "OVR_NB_pipeline = Pipeline([\n",
    "                ('Vectorizer', CountVectorizer(stop_words='english')),\n",
    "                ('MultiNB', OneVsRestClassifier(MultinomialNB(alpha=best_alpha) ))    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating classification models\n",
    "\n",
    "models = {\"Logistic Regression\": LogisticRegression(), \n",
    "          \"KNN\": KNeighborsClassifier(), \n",
    "          \"DecisionTree\": DecisionTreeClassifier(),\n",
    "          \"LinearSVC\": LinearSVC()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'professor marvin h mills is a self published crank his book is printed by iuniverse a vanity publishing company mills also believes that the mosques in spain were built by phoenicians aided by survivors from atlantis we learn of the piri reis map that it lead ivar zapp and george erikson in atlantis in america to assert that an awareness of antartica was known to an advanced civilization at the end of the ice age and yes the published version of this book really does spell the second word of that sentence with an a mills is not a reliable source he is self published and his views are fringe'"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "X_train = train_df['cleaner_text']\n",
    "y = train_labels\n",
    "\n",
    "X = CountVectorizer(stop_words='english').fit_transform(train_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment_text  toxic  \\\n",
      "159281  LoL!! \\n\\nyou're GAY!! you will never know how...      1   \n",
      "159336  Oh, fuck off. The pansy Jew would just whine a...      1   \n",
      "159400  Shalom \\n\\nSemite, get the fuck out of here. I...      1   \n",
      "159449                         I think he is a gay fag!!!      1   \n",
      "159494  \"\\n\\n our previous conversation \\n\\nyou fuckin...      1   \n",
      "\n",
      "        severe_toxic  obscene  threat  insult  identity_hate  \\\n",
      "159281             1        1       0       1              1   \n",
      "159336             0        1       0       1              1   \n",
      "159400             1        1       1       1              1   \n",
      "159449             0        0       0       0              1   \n",
      "159494             0        1       0       1              1   \n",
      "\n",
      "                                             cleaner_text  \n",
      "159281         lol gay never know good feel fuck woman as  \n",
      "159336  oh fuck pansy jew would whine bnai brith beat ...  \n",
      "159400  shalom semite get fuck kill son bitch leave wi...  \n",
      "159449                                      think gay fag  \n",
      "159494  previous conversation fucking shit eating libe...  \n"
     ]
    }
   ],
   "source": [
    "fltr = train_df[train_df['identity_hate'] == 1] \n",
    "print(fltr.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m kf \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m     20\u001b[0m score_evals \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbalanced_accuracy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mneg_log_loss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> 21\u001b[0m cv \u001b[39m=\u001b[39m cross_validate(NB, X_rus, y_rus, cv\u001b[39m=\u001b[39mkf, scoring \u001b[39m=\u001b[39m score_evals, return_estimator\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m cv_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(cv)\n\u001b[0;32m     24\u001b[0m cv_df\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mfit_time\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mscore_time\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mestimator\u001b[39m\u001b[39m'\u001b[39m], axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m, inplace \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'NB' is not defined"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, cross_validate\n",
    "\n",
    "smote = SMOTE()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "MultiNB = MultinomialNB() # NB takes ~10s to train all labels\n",
    "LR = LogisticRegression()  # LR takes > 2 min to train all labels\n",
    "\n",
    "cv_all = pd.DataFrame()\n",
    "\n",
    "for label in LABELS:\n",
    "    \n",
    "    X_smote, y_smote = smote.fit_resample(X_train, y_train[label])\n",
    "    X_rus, y_rus = rus.fit_resample(X_train, y_train[label])\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    score_evals = ['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1', 'neg_log_loss']\n",
    "    cv = cross_validate(MultiNB, X_rus, y_rus, cv=kf, scoring = score_evals, return_estimator=True)\n",
    "\n",
    "    cv_df = pd.DataFrame(cv)\n",
    "    cv_df.drop(['fit_time', 'score_time', 'estimator'], axis = 1, inplace = True) \n",
    "    \n",
    "    print('Processing {} label'.format(label))\n",
    "    display(cv_df)\n",
    "    \n",
    "    cv_mean = cv_df.mean()\n",
    "    cv_all = pd.concat([cv_all, cv_mean], axis=1)\n",
    "\n",
    "cv_all.columns = LABELS  # set the column names\n",
    "cv_all.index = score_evals # set the index names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.870377</td>\n",
       "      <td>0.933735</td>\n",
       "      <td>0.898608</td>\n",
       "      <td>0.905745</td>\n",
       "      <td>0.885564</td>\n",
       "      <td>0.896111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.870415</td>\n",
       "      <td>0.933776</td>\n",
       "      <td>0.898580</td>\n",
       "      <td>0.906563</td>\n",
       "      <td>0.885614</td>\n",
       "      <td>0.896211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.905824</td>\n",
       "      <td>0.929323</td>\n",
       "      <td>0.919712</td>\n",
       "      <td>0.897129</td>\n",
       "      <td>0.921038</td>\n",
       "      <td>0.908770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.826770</td>\n",
       "      <td>0.939017</td>\n",
       "      <td>0.873505</td>\n",
       "      <td>0.916965</td>\n",
       "      <td>0.843389</td>\n",
       "      <td>0.880695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.864450</td>\n",
       "      <td>0.934103</td>\n",
       "      <td>0.895991</td>\n",
       "      <td>0.906433</td>\n",
       "      <td>0.880408</td>\n",
       "      <td>0.894397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg_log_loss</th>\n",
       "      <td>-0.837107</td>\n",
       "      <td>-0.434362</td>\n",
       "      <td>-0.773476</td>\n",
       "      <td>-0.540937</td>\n",
       "      <td>-0.808088</td>\n",
       "      <td>-0.628440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      toxic  severe_toxic   obscene    threat    insult  \\\n",
       "accuracy           0.870377      0.933735  0.898608  0.905745  0.885564   \n",
       "balanced_accuracy  0.870415      0.933776  0.898580  0.906563  0.885614   \n",
       "precision          0.905824      0.929323  0.919712  0.897129  0.921038   \n",
       "recall             0.826770      0.939017  0.873505  0.916965  0.843389   \n",
       "f1                 0.864450      0.934103  0.895991  0.906433  0.880408   \n",
       "neg_log_loss      -0.837107     -0.434362 -0.773476 -0.540937 -0.808088   \n",
       "\n",
       "                   identity_hate  \n",
       "accuracy                0.896111  \n",
       "balanced_accuracy       0.896211  \n",
       "precision               0.908770  \n",
       "recall                  0.880695  \n",
       "f1                      0.894397  \n",
       "neg_log_loss           -0.628440  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(cv_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy             0.911811\n",
       "balanced_accuracy    0.911623\n",
       "precision            0.939029\n",
       "recall               0.881478\n",
       "f1                   0.909142\n",
       "neg_log_loss        -0.280026\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_all.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_all.to_csv('scores_LR_rus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index(['test_balanced_accuracy', 'test_precision', 'test_recall', 'test_f1',\n",
      "       'test_neg_log_loss'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(type(cv_df.mean()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properly evaluate with testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, cross_validate\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "smote = SMOTE()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "# model = MultinomialNB() # NB takes ~10s to train all labels\n",
    "model = LogisticRegression()  # LR takes > 2 min to train all labels\n",
    "\n",
    "label = 'obscene'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y[label], test_size=0.2)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "def model_train_evaluate(model, X_train, y_train, X_test, y_test, dec=2, verbose=False):\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "\n",
    "    # print('Processing {} label'.format(label))\n",
    "    # print(classification_report(y_test, pred, output_dict=False))\n",
    "    bal_acc = np.round(balanced_accuracy_score(y_test, pred), dec)\n",
    "    prec, rec, f1 = np.round(precision_recall_fscore_support(y_test, pred, average='binary', pos_label=1)[:3] , dec)\n",
    "    CM = confusion_matrix(y_test, pred)\n",
    "    TN, FN, TP, FP = CM[0][0], CM[1][0], CM[1][1], CM[0][1]\n",
    "    if verbose:\n",
    "        print('bal_acc: {}, precision: {}, recall: {}, f1: {}'.format(bal_acc, prec, rec, f1) )  \n",
    "    \n",
    "    return bal_acc, prec, rec, f1, TN, FN, TP, FP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_all_labels(models, X, y, label='toxic', verbose=False):\n",
    "    '''\n",
    "    models: dict, for iterating through classifier models\n",
    "    X, y: pd.DataFrame, array-like\n",
    "    label: string that matches the columns of data\n",
    "    verbose: bool, for optional print outs\n",
    "    '''\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y[label], test_size=0.2) # Original split\n",
    "    X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train) # Random Under Sampling (RUS)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train) #Synthetic Oversampling (SMOTE)\n",
    "    \n",
    "    n_0, n_1 = y_train.value_counts()\n",
    "    imbalance_ratio = np.round(n_1/(n_0 + n_1), 3)\n",
    "    \n",
    "    train_sets = {'Original': [X_train, y_train], \n",
    "                    'RUS': [X_train_rus, y_train_rus], \n",
    "                    'SMOTE': [X_train_smote, y_train_smote]}\n",
    "    \n",
    "    scores = pd.DataFrame()  # initialize empty DF to store everything\n",
    "    \n",
    "    # iterate through the different training sets, must be in dictionary format\n",
    "    for train_split, train_data in train_sets.items():  \n",
    "        X_input, y_input = train_data\n",
    "        \n",
    "        # iterate through the classifier models, must be in dictionary format\n",
    "        for model_name, model in models.items(): \n",
    "            \n",
    "            bal_acc, prec, rec, f1, TN, FN, TP, FP = model_train_evaluate(model, X_input, y_input, X_test, y_test, verbose= verbose)\n",
    "            scores = scores.append({'label': label,\n",
    "                                    'imbalance_ratio': imbalance_ratio, \n",
    "                                    'clf_model': model_name,\n",
    "                                    'train_split': train_split,\n",
    "                                    'balanced_accuracy': bal_acc,\n",
    "                                    'precision': prec,\n",
    "                                    'recall': rec,\n",
    "                                    'f1_score': f1,\n",
    "                                    'TN': TN, 'FN': FN, 'TP': TP, 'FP': FP,}, ignore_index=True)\n",
    "            \n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 16s\n",
      "Wall time: 1min 18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\3628545022.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "models = {'MultinomialNB': MultinomialNB(), 'LogisticRegression': LogisticRegression()}\n",
    "all_scores= pd.DataFrame()\n",
    "LABELS = ['toxic', 'obscene', 'insult', 'severe_toxic', 'identity_hate', 'threat']\n",
    "\n",
    "\n",
    "for label in LABELS:\n",
    "    scores = train_evaluate_all_labels(models, X, y, label=label, verbose=False)\n",
    "    # print(scores)\n",
    "    all_scores = pd.concat([all_scores, scores], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\462376751.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  display(all_scores.groupby(['label']).mean().sort_values(by='imbalance_ratio'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imbalance_ratio</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>threat</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.111667</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.118333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identity_hate</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.718333</td>\n",
       "      <td>0.161667</td>\n",
       "      <td>0.473333</td>\n",
       "      <td>0.173333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe_toxic</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.223333</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.276667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insult</th>\n",
       "      <td>0.049</td>\n",
       "      <td>0.823333</td>\n",
       "      <td>0.496667</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.546667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obscene</th>\n",
       "      <td>0.052</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>0.096</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               imbalance_ratio  balanced_accuracy  precision    recall  \\\n",
       "label                                                                    \n",
       "threat                   0.003           0.710000   0.111667  0.460000   \n",
       "identity_hate            0.009           0.718333   0.161667  0.473333   \n",
       "severe_toxic             0.010           0.791667   0.223333  0.615000   \n",
       "insult                   0.049           0.823333   0.496667  0.695000   \n",
       "obscene                  0.052           0.853333   0.575000  0.740000   \n",
       "toxic                    0.096           0.836667   0.615000  0.735000   \n",
       "\n",
       "               f1_score  \n",
       "label                    \n",
       "threat         0.118333  \n",
       "identity_hate  0.173333  \n",
       "severe_toxic   0.276667  \n",
       "insult         0.546667  \n",
       "obscene        0.625000  \n",
       "toxic          0.650000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\462376751.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  display(all_scores.groupby(['clf_model']).mean())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imbalance_ratio</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.797778</td>\n",
       "      <td>0.381111</td>\n",
       "      <td>0.641111</td>\n",
       "      <td>0.403889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>0.598333</td>\n",
       "      <td>0.392778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    imbalance_ratio  balanced_accuracy  precision    recall  \\\n",
       "clf_model                                                                     \n",
       "LogisticRegression           0.0365           0.797778   0.381111  0.641111   \n",
       "MultinomialNB                0.0365           0.780000   0.346667  0.598333   \n",
       "\n",
       "                    f1_score  \n",
       "clf_model                     \n",
       "LogisticRegression  0.403889  \n",
       "MultinomialNB       0.392778  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_21424\\462376751.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  display(all_scores.groupby(['train_split']).mean())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imbalance_ratio</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Original</th>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.397500</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RUS</th>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.280833</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.3850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE</th>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.775833</td>\n",
       "      <td>0.304167</td>\n",
       "      <td>0.596667</td>\n",
       "      <td>0.3725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             imbalance_ratio  balanced_accuracy  precision    recall  f1_score\n",
       "train_split                                                                   \n",
       "Original              0.0365           0.693333   0.506667  0.397500    0.4375\n",
       "RUS                   0.0365           0.897500   0.280833  0.865000    0.3850\n",
       "SMOTE                 0.0365           0.775833   0.304167  0.596667    0.3725"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(all_scores)\n",
    "display(all_scores.groupby(['label']).mean().sort_values(by='imbalance_ratio'))\n",
    "display(all_scores.groupby(['clf_model']).mean())\n",
    "display(all_scores.groupby(['train_split']).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": [
     "grid search df"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>imbalance_ratio</th>\n",
       "      <th>clf_model</th>\n",
       "      <th>train_split</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.053</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.76</td>\n",
       "      <td>30078</td>\n",
       "      <td>534</td>\n",
       "      <td>1129</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.097</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.73</td>\n",
       "      <td>28566</td>\n",
       "      <td>1047</td>\n",
       "      <td>1919</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.053</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.69</td>\n",
       "      <td>29098</td>\n",
       "      <td>176</td>\n",
       "      <td>1487</td>\n",
       "      <td>1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.097</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.66</td>\n",
       "      <td>26680</td>\n",
       "      <td>378</td>\n",
       "      <td>2588</td>\n",
       "      <td>2269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.097</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.66</td>\n",
       "      <td>28203</td>\n",
       "      <td>1143</td>\n",
       "      <td>1823</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.097</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.64</td>\n",
       "      <td>27928</td>\n",
       "      <td>1094</td>\n",
       "      <td>1872</td>\n",
       "      <td>1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.053</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.63</td>\n",
       "      <td>29487</td>\n",
       "      <td>558</td>\n",
       "      <td>1105</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.053</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.62</td>\n",
       "      <td>29695</td>\n",
       "      <td>676</td>\n",
       "      <td>987</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.097</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.62</td>\n",
       "      <td>26514</td>\n",
       "      <td>541</td>\n",
       "      <td>2425</td>\n",
       "      <td>2435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.050</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.61</td>\n",
       "      <td>30120</td>\n",
       "      <td>766</td>\n",
       "      <td>784</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.050</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.58</td>\n",
       "      <td>29521</td>\n",
       "      <td>581</td>\n",
       "      <td>969</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.050</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.57</td>\n",
       "      <td>28498</td>\n",
       "      <td>181</td>\n",
       "      <td>1369</td>\n",
       "      <td>1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.050</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>29750</td>\n",
       "      <td>700</td>\n",
       "      <td>850</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.097</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.55</td>\n",
       "      <td>25786</td>\n",
       "      <td>629</td>\n",
       "      <td>2337</td>\n",
       "      <td>3163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.053</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.54</td>\n",
       "      <td>27974</td>\n",
       "      <td>202</td>\n",
       "      <td>1461</td>\n",
       "      <td>2278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.053</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.51</td>\n",
       "      <td>27952</td>\n",
       "      <td>313</td>\n",
       "      <td>1350</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.050</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.51</td>\n",
       "      <td>28065</td>\n",
       "      <td>217</td>\n",
       "      <td>1333</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.050</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.43</td>\n",
       "      <td>27596</td>\n",
       "      <td>355</td>\n",
       "      <td>1195</td>\n",
       "      <td>2769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.010</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.39</td>\n",
       "      <td>31121</td>\n",
       "      <td>137</td>\n",
       "      <td>191</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.010</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.36</td>\n",
       "      <td>31297</td>\n",
       "      <td>192</td>\n",
       "      <td>136</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.010</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.33</td>\n",
       "      <td>31501</td>\n",
       "      <td>246</td>\n",
       "      <td>82</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.010</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.32</td>\n",
       "      <td>30375</td>\n",
       "      <td>37</td>\n",
       "      <td>291</td>\n",
       "      <td>1212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.003</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.26</td>\n",
       "      <td>31790</td>\n",
       "      <td>75</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.009</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.24</td>\n",
       "      <td>30986</td>\n",
       "      <td>163</td>\n",
       "      <td>125</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.010</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.22</td>\n",
       "      <td>29490</td>\n",
       "      <td>30</td>\n",
       "      <td>298</td>\n",
       "      <td>2097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.010</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.20</td>\n",
       "      <td>29918</td>\n",
       "      <td>106</td>\n",
       "      <td>222</td>\n",
       "      <td>1669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.009</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.20</td>\n",
       "      <td>29635</td>\n",
       "      <td>35</td>\n",
       "      <td>253</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.009</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>31398</td>\n",
       "      <td>237</td>\n",
       "      <td>51</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.009</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.15</td>\n",
       "      <td>28912</td>\n",
       "      <td>41</td>\n",
       "      <td>247</td>\n",
       "      <td>2715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.009</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.14</td>\n",
       "      <td>31558</td>\n",
       "      <td>261</td>\n",
       "      <td>27</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.009</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.12</td>\n",
       "      <td>29706</td>\n",
       "      <td>147</td>\n",
       "      <td>141</td>\n",
       "      <td>1921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.003</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.09</td>\n",
       "      <td>31415</td>\n",
       "      <td>70</td>\n",
       "      <td>24</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.003</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.07</td>\n",
       "      <td>29632</td>\n",
       "      <td>13</td>\n",
       "      <td>81</td>\n",
       "      <td>2189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.003</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.05</td>\n",
       "      <td>28988</td>\n",
       "      <td>15</td>\n",
       "      <td>79</td>\n",
       "      <td>2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.003</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.05</td>\n",
       "      <td>30497</td>\n",
       "      <td>61</td>\n",
       "      <td>33</td>\n",
       "      <td>1324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.003</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>31726</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label  imbalance_ratio           clf_model train_split  \\\n",
       "1        obscene            0.053  LogisticRegression    Original   \n",
       "1          toxic            0.097  LogisticRegression    Original   \n",
       "3        obscene            0.053  LogisticRegression         RUS   \n",
       "3          toxic            0.097  LogisticRegression         RUS   \n",
       "0          toxic            0.097       MultinomialNB    Original   \n",
       "4          toxic            0.097       MultinomialNB       SMOTE   \n",
       "4        obscene            0.053       MultinomialNB       SMOTE   \n",
       "0        obscene            0.053       MultinomialNB    Original   \n",
       "2          toxic            0.097       MultinomialNB         RUS   \n",
       "1         insult            0.050  LogisticRegression    Original   \n",
       "4         insult            0.050       MultinomialNB       SMOTE   \n",
       "3         insult            0.050  LogisticRegression         RUS   \n",
       "0         insult            0.050       MultinomialNB    Original   \n",
       "5          toxic            0.097  LogisticRegression       SMOTE   \n",
       "2        obscene            0.053       MultinomialNB         RUS   \n",
       "5        obscene            0.053  LogisticRegression       SMOTE   \n",
       "2         insult            0.050       MultinomialNB         RUS   \n",
       "5         insult            0.050  LogisticRegression       SMOTE   \n",
       "4   severe_toxic            0.010       MultinomialNB       SMOTE   \n",
       "0   severe_toxic            0.010       MultinomialNB    Original   \n",
       "1   severe_toxic            0.010  LogisticRegression    Original   \n",
       "3   severe_toxic            0.010  LogisticRegression         RUS   \n",
       "1         threat            0.003  LogisticRegression    Original   \n",
       "4  identity_hate            0.009       MultinomialNB       SMOTE   \n",
       "2   severe_toxic            0.010       MultinomialNB         RUS   \n",
       "5   severe_toxic            0.010  LogisticRegression       SMOTE   \n",
       "3  identity_hate            0.009  LogisticRegression         RUS   \n",
       "0  identity_hate            0.009       MultinomialNB    Original   \n",
       "2  identity_hate            0.009       MultinomialNB         RUS   \n",
       "1  identity_hate            0.009  LogisticRegression    Original   \n",
       "5  identity_hate            0.009  LogisticRegression       SMOTE   \n",
       "4         threat            0.003       MultinomialNB       SMOTE   \n",
       "3         threat            0.003  LogisticRegression         RUS   \n",
       "2         threat            0.003       MultinomialNB         RUS   \n",
       "5         threat            0.003  LogisticRegression       SMOTE   \n",
       "0         threat            0.003       MultinomialNB    Original   \n",
       "\n",
       "   balanced_accuracy  precision  recall  f1_score     TN    FN    TP    FP  \n",
       "1               0.84       0.87    0.68      0.76  30078   534  1129   174  \n",
       "1               0.82       0.83    0.65      0.73  28566  1047  1919   383  \n",
       "3               0.93       0.56    0.89      0.69  29098   176  1487  1154  \n",
       "3               0.90       0.53    0.87      0.66  26680   378  2588  2269  \n",
       "0               0.79       0.71    0.61      0.66  28203  1143  1823   746  \n",
       "4               0.80       0.65    0.63      0.64  27928  1094  1872  1021  \n",
       "4               0.82       0.59    0.66      0.63  29487   558  1105   765  \n",
       "0               0.79       0.64    0.59      0.62  29695   676   987   557  \n",
       "2               0.87       0.50    0.82      0.62  26514   541  2425  2435  \n",
       "1               0.75       0.76    0.51      0.61  30120   766   784   245  \n",
       "4               0.80       0.53    0.63      0.58  29521   581   969   844  \n",
       "3               0.91       0.42    0.88      0.57  28498   181  1369  1867  \n",
       "0               0.76       0.58    0.55      0.56  29750   700   850   615  \n",
       "5               0.84       0.42    0.79      0.55  25786   629  2337  3163  \n",
       "2               0.90       0.39    0.88      0.54  27974   202  1461  2278  \n",
       "5               0.87       0.37    0.81      0.51  27952   313  1350  2300  \n",
       "2               0.89       0.37    0.86      0.51  28065   217  1333  2300  \n",
       "5               0.84       0.30    0.77      0.43  27596   355  1195  2769  \n",
       "4               0.78       0.29    0.58      0.39  31121   137   191   466  \n",
       "0               0.70       0.32    0.41      0.36  31297   192   136   290  \n",
       "1               0.62       0.49    0.25      0.33  31501   246    82    86  \n",
       "3               0.92       0.19    0.89      0.32  30375    37   291  1212  \n",
       "1               0.60       0.38    0.20      0.26  31790    75    19    31  \n",
       "4               0.71       0.16    0.43      0.24  30986   163   125   641  \n",
       "2               0.92       0.12    0.91      0.22  29490    30   298  2097  \n",
       "5               0.81       0.12    0.68      0.20  29918   106   222  1669  \n",
       "3               0.91       0.11    0.88      0.20  29635    35   253  1992  \n",
       "0               0.58       0.18    0.18      0.18  31398   237    51   229  \n",
       "2               0.89       0.08    0.86      0.15  28912    41   247  2715  \n",
       "1               0.55       0.28    0.09      0.14  31558   261    27    69  \n",
       "5               0.71       0.07    0.49      0.12  29706   147   141  1921  \n",
       "4               0.62       0.06    0.26      0.09  31415    70    24   406  \n",
       "3               0.90       0.04    0.86      0.07  29632    13    81  2189  \n",
       "2               0.88       0.03    0.84      0.05  28988    15    79  2833  \n",
       "5               0.65       0.02    0.35      0.05  30497    61    33  1324  \n",
       "0               0.51       0.02    0.02      0.02  31726    92     2    95  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(all_scores.sort_values(by='f1_score', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "1\n",
      "2\n",
      "b\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# trying different classifiers\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9607903993378853\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(pred, y_test)\n",
    "\n",
    "tp, fp, tn, fn = cm[1,1], cm [1,0], cm[0,0], cm[0,1]  # 1's are true\n",
    "tp, fp, tn, fn = cm[0,0], cm [0,1], cm[1,1], cm[1,0]  # 0's are true\n",
    "\n",
    "prec = tp/(tp+fp)\n",
    "print(prec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6e42a3d7400be7cc1f2873a41239adfc85a71a2b7bd4dd5b538442f24ae4903"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
