{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Feng\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from joblib import load\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier # used with Linear SVC\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from multilabel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "del_punct = string.punctuation\n",
    "del_punct = del_punct.replace(\"-\", \"\")  # don't remove hyphens\n",
    "rm_pattern = r\"[{}]\".format(del_punct)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # convert to all lower case\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub(rm_pattern, \"\", text)  # remove punctuations\n",
    "    text = re.sub(r'[0-9]', ' ', text)  # remove digits 0-9\n",
    "    text = re.sub('\\W', ' ', text)   # removes non-word character\n",
    "    text = re.sub('\\s+', ' ', text)  # removes extra spaces\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Feng\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Define stopwords to exclude\n",
    "stop = set(stopwords.words('english'))\n",
    "stop.update((\"to\",\"cc\",\"subject\",\"http\",\"from\",\"sent\", \"ect\", \"u\", \"fwd\", \"www\", \"com\"))\n",
    "\n",
    "# Define punctuations to exclude and lemmatizer\n",
    "exclude = set(string.punctuation)\n",
    "\n",
    "# df_processed_text = pd.read_csv('processed_text.csv', usecols = ['cleaned_text'])\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def text_lemmatizer(text):     \n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_text = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        # lemmatized = wordnet_lemmatizer.lemmatize(token, pos='v')\n",
    "        lemmatized_text.append(wordnet_lemmatizer.lemmatize(token, pos='v'))\n",
    "        lemmatized_text.append(' ')\n",
    "        \n",
    "    return ''.join(lemmatized_text)\n",
    "\n",
    "def text_cleaner(text, stop):\n",
    "    text = clean_text(text)\n",
    "    stop_free = \" \".join([i for i in text.lower().split() if((i not in stop) and (not i.isdigit()))])\n",
    "    punc_free = ''.join(i for i in stop_free if i not in exclude)\n",
    "    normalized = \" \".join(wordnet_lemmatizer.lemmatize(i) for i in punc_free.split())  \n",
    "    \n",
    "    return normalized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_text) == len(train_labels)\n",
    "dataset_directory = \"C:/Users/Feng/Coding projects/toxic-comments-datasets/\"\n",
    "train_df = pd.read_csv(dataset_directory + \"train.csv.zip\", usecols = ['comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'])\n",
    "train_df = train_df.astype({'toxic':'int16',\n",
    "                            'severe_toxic':'int16',\n",
    "                            'obscene':'int16',\n",
    "                            'threat':'int16',\n",
    "                            'insult':'int16',\n",
    "                            'identity_hate':'int16'})\n",
    "\n",
    "train_df = train_df.dropna()  # I found 5 nan rows in cleaned_text, so I just drop those rows altogether\n",
    "# print(train_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 28.4 s\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df['cleaner_text'] = train_df['comment_text'].map(lambda comments : text_cleaner(comments, stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159096    filthy stinking crow back dirty crow better de...\n",
       "159099          fucking pathetic moron jimbo wale rootmyass\n",
       "159281           lol gay never know good feel fuck woman as\n",
       "159312    walter mercado antonio quite frankly fucker co...\n",
       "159400    shalom semite get fuck kill son bitch leave wi...\n",
       "Name: cleaner_text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(train_df.info())\n",
    "display(train_df[train_df.severe_toxic==1]['cleaner_text'].tail())\n",
    "# print(train_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    explanation why the edits made under my userna...\n",
      "1    daww he matches this background colour i am se...\n",
      "2    hey man i am really not trying to edit war it ...\n",
      "3    more i can not make any real suggestions on im...\n",
      "4    you sir are my hero any chance you remember wh...\n",
      "Name: cleaned_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_df['cleaned_text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "train_text = train_df['cleaned_text']\n",
    "train_labels = train_df[LABELS]\n",
    "\n",
    "X_train_m, X_test_m, y_train_m, y_test_M = multilabel_train_test_split(train_text, train_labels, size=0.25)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_text, train_labels, test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline combining a text feature extractor with multi lable classifier\n",
    "countvec_NB_pipeline = Pipeline([\n",
    "                ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "                ('clf', MultinomialNB()) ])\n",
    "\n",
    "tfidf_NB_pipeline = Pipeline([\n",
    "                ('vectorizer', TfidfVectorizer(stop_words='english')),\n",
    "                ('clf', MultinomialNB()) ])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision vs Recall\n",
    "\n",
    "Precision = TP/(TP+FP)\n",
    "\n",
    "Recall = TP/(TP+FN)\n",
    "\n",
    "FP = good comments wrongfully labeled toxic\n",
    "\n",
    "FN = undetected toxic comments\n",
    "\n",
    "Having high accuracy is misleading, since positive toxic labels are sparse. The question is, do I want high precision or high recall. Precision is a measure of true positives (correctly labeled toxic comments) relative to false positives (clean comments wrongfully labeled toxic). Recall measures true positives relative to false negatives (toxic comments that were not detected). In other words, do I want to minimize wrongfully labeled clean comments or undetected toxic comments. In my opinion, the former is preferred, since randomly deleting clean comments will upset users. Therefore, high precision is more preferred than high recall."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVec + NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy', 'precision', 'recall', 'f1']\n",
      "... Processing toxic\n",
      "[0.95 0.82 0.6  0.69]\n",
      "... Processing severe_toxic\n",
      "[0.99 0.46 0.42 0.44]\n",
      "... Processing obscene\n",
      "[0.97 0.79 0.58 0.67]\n",
      "... Processing threat\n",
      "[1.   0.25 0.06 0.09]\n",
      "... Processing insult\n",
      "[0.97 0.72 0.51 0.6 ]\n",
      "... Processing identity_hate\n",
      "[0.99 0.28 0.11 0.16]\n",
      "               accuracy  precision  recall    f1\n",
      "toxic              0.95       0.82    0.60  0.69\n",
      "severe_toxic       0.99       0.46    0.42  0.44\n",
      "obscene            0.97       0.79    0.58  0.67\n",
      "threat             1.00       0.25    0.06  0.09\n",
      "insult             0.97       0.72    0.51  0.60\n",
      "identity_hate      0.99       0.28    0.11  0.16\n"
     ]
    }
   ],
   "source": [
    "scores_dict = {}\n",
    "print(['accuracy', 'precision', 'recall', 'f1'])\n",
    "for label in LABELS:\n",
    "    print('... Processing {}'.format(label))\n",
    "    # train the model using X_dtm & y\n",
    "    # countvec_NB_pipeline.fit(X_train.iloc[0:10000], y_train[label].iloc[0:10000]) # train with a slice \n",
    "    countvec_NB_pipeline.fit(X_train, y_train[label])  # train with whole dataset\n",
    "\n",
    "    # compute the testing accuracy\n",
    "    pred = countvec_NB_pipeline.predict(X_test)\n",
    "    test = y_test[label]\n",
    "    \n",
    "    scores = [accuracy_score(test, pred), precision_score(test, pred), recall_score(test, pred), f1_score(test, pred) ] \n",
    "    scores_dict[label] = scores\n",
    "    # scores = np.round(scores, decimals = 2)\n",
    "    \n",
    "    print(np.round(scores, decimals = 2))\n",
    "\n",
    "pred_scores = pd.DataFrame(scores_dict, index=['accuracy', 'precision', 'recall', 'f1'])\n",
    "print(np.round(pred_scores.T, decimals=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF + NB\n",
    "TFIDF completely failed on precision and recall for the very sparse labels e.g. severe_toxic, threat, identity_hate. These 3 labels have < 1% of occurence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy', 'precision', 'recall', 'f1']\n",
      "... Processing toxic\n",
      "[0.92 0.99 0.18 0.31]\n",
      "... Processing severe_toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99 0.   0.   0.  ]\n",
      "... Processing obscene\n",
      "[0.95 0.99 0.12 0.21]\n",
      "... Processing threat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0.]\n",
      "... Processing insult\n",
      "[0.95 0.95 0.05 0.09]\n",
      "... Processing identity_hate\n",
      "[0.99 0.   0.   0.  ]\n",
      "               accuracy  precision  recall    f1\n",
      "toxic              0.92       0.99    0.18  0.31\n",
      "severe_toxic       0.99       0.00    0.00  0.00\n",
      "obscene            0.95       0.99    0.12  0.21\n",
      "threat             1.00       0.00    0.00  0.00\n",
      "insult             0.95       0.95    0.05  0.09\n",
      "identity_hate      0.99       0.00    0.00  0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores_dict = {}\n",
    "print(['accuracy', 'precision', 'recall', 'f1'])\n",
    "for label in LABELS:\n",
    "    print('... Processing {}'.format(label))\n",
    "    # train the model using X_dtm & y\n",
    "    # countvec_NB_pipeline.fit(X_train.iloc[0:10000], y_train[label].iloc[0:10000]) # train with a slice \n",
    "    tfidf_NB_pipeline.fit(X_train, y_train[label])  # train with whole dataset\n",
    "\n",
    "    # compute the testing accuracy\n",
    "    pred = tfidf_NB_pipeline.predict(X_test)\n",
    "    test = y_test[label]\n",
    "    \n",
    "    scores = [accuracy_score(test, pred), precision_score(test, pred), recall_score(test, pred), f1_score(test, pred) ] \n",
    "    scores_dict[label] = scores\n",
    "    \n",
    "    print(np.round(scores, decimals = 2))\n",
    "\n",
    "scores_tfidf_NB = pd.DataFrame(scores_dict, index=['accuracy', 'precision', 'recall', 'f1']).T\n",
    "print(np.round(scores_tfidf_NB, decimals=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Tfidf to BoW\n",
    "Based on metrics of recall and f1, **BoW** is the clear winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------CountVectorizer scores----------\n",
      "               accuracy  precision  recall    f1\n",
      "toxic              0.95       0.83    0.59  0.69\n",
      "severe_toxic       0.99       0.47    0.42  0.44\n",
      "obscene            0.97       0.78    0.59  0.67\n",
      "threat             1.00       0.07    0.02  0.03\n",
      "insult             0.97       0.71    0.51  0.59\n",
      "identity_hate      0.99       0.35    0.13  0.19\n",
      "-- Mean scores --\n",
      "accuracy     0.977167\n",
      "precision    0.535365\n",
      "recall       0.374957\n",
      "f1           0.434943\n",
      "dtype: float64\n",
      "--------TfidfVectorizer scores----------\n",
      "               accuracy  precision  recall    f1\n",
      "toxic              0.92       0.99    0.18  0.31\n",
      "severe_toxic       0.99       0.00    0.00  0.00\n",
      "obscene            0.95       0.99    0.12  0.21\n",
      "threat             1.00       0.00    0.00  0.00\n",
      "insult             0.95       0.95    0.05  0.09\n",
      "identity_hate      0.99       0.00    0.00  0.00\n",
      "-- Mean scores --\n",
      "accuracy     0.968234\n",
      "precision    0.488181\n",
      "recall       0.057397\n",
      "f1           0.100589\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "scores_count_NB = pred_scores.T\n",
    "print('--------CountVectorizer scores----------')\n",
    "print(np.round(scores_count_NB, 2))\n",
    "print('-- Mean scores --')\n",
    "print(scores_count_NB.mean())\n",
    "print('--------TfidfVectorizer scores----------')\n",
    "print(np.round(scores_tfidf_NB, 2))\n",
    "print('-- Mean scores --')\n",
    "print(scores_tfidf_NB.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(stop_words='english')),\n",
       "                ('clf', OneVsRestClassifier(estimator=MultinomialNB()))])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a pipeline combining a text feature extractor with multi lable classifier\n",
    "OVR_NB_pipeline = Pipeline([\n",
    "                # ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None))),\n",
    "            ])\n",
    "\n",
    "OVR_NB_pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OVR_NB_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[39m=\u001b[39m OVR_NB_pipeline\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      2\u001b[0m y_proba \u001b[39m=\u001b[39m OVR_NB_pipeline\u001b[39m.\u001b[39mpredict_proba(X_test)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(LABELS)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'OVR_NB_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = OVR_NB_pipeline.predict(X_test)\n",
    "y_proba = OVR_NB_pipeline.predict_proba(X_test)\n",
    "\n",
    "print(LABELS)\n",
    "multi_cm = multilabel_confusion_matrix(y_test, y_pred, samplewise=False)\n",
    "\n",
    "for i in range(multi_cm.shape[0]):\n",
    "    #[[TN, FP],\n",
    "    # [FN, TP]]\n",
    "    print(LABELS[i])\n",
    "    print(multi_cm[i,:,:])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_table(test, pred, proba):\n",
    "    \n",
    "    hamming_losses = []\n",
    "    acc_scores = []\n",
    "    bal_acc_scores = []\n",
    "    roc_auc_scores = []\n",
    "    scores_multi = {}\n",
    "\n",
    "    for i, label in enumerate(LABELS):\n",
    "        \n",
    "        acc = accuracy_score(test[:,i], pred[:,i])\n",
    "        acc_scores.append(acc)\n",
    "        \n",
    "        bal_acc = balanced_accuracy_score(test[:,i], pred[:,i])\n",
    "        bal_acc_scores.append(bal_acc)\n",
    "        \n",
    "        # hamming = hamming_loss(test[:,i], pred[:,i])\n",
    "        # hamming_losses.append(hamming)\n",
    "\n",
    "        roc_auc = roc_auc_score(test[:,i], proba[:,i])\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        \n",
    "    scores_multi['accuracy']= acc_scores\n",
    "    scores_multi['balanced_accuracy']= bal_acc_scores\n",
    "    scores_multi['roc_auc_score'] = roc_auc_scores\n",
    "    # scores_multi['hamming_loss']= hamming_losses  # hamming_loss isn't that useful\n",
    "    \n",
    "    scores_multi['precision'] = precision_score(test, pred, average=None) \n",
    "    scores_multi['recall'] = recall_score(test, pred, average=None) \n",
    "    scores_multi['f1'] = f1_score(test, pred, average=None) \n",
    "\n",
    "    scores_multi_df = pd.DataFrame(scores_multi, index = LABELS)\n",
    "    print(np.round(scores_multi_df,3))\n",
    "    \n",
    "    return scores_multi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m test \u001b[39m=\u001b[39m y_test\u001b[39m.\u001b[39mvalues  \u001b[39m# y_test is a DataFrame, so it must be converted into nd.array\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m pred \u001b[39m=\u001b[39m y_pred  \u001b[39m# binary predictions for each label\u001b[39;00m\n\u001b[0;32m      3\u001b[0m proba \u001b[39m=\u001b[39m y_proba \u001b[39m# probabilities for each prediction\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmetrics_table\u001b[39m(test, pred, proba):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "test = y_test.values  # y_test is a DataFrame, so it must be converted into nd.array\n",
    "pred = y_pred  # binary predictions for each label\n",
    "proba = y_proba # probabilities for each prediction\n",
    "\n",
    "scores_multi_df = metrics_table(test, pred, proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
    "\n",
    "param_grid = {'alpha': np.arange(0.0001, 1, 5)}\n",
    "\n",
    "# Define a pipeline combining a text feature extractor with multi lable classifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_text, train_labels, test_size=0.25)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
      "0      0             0        0       0       0                0.898432\n",
      "1      0             0        0       0       0                0.035380\n",
      "                     1        0       1       0                0.023639\n",
      "                                      0       0                0.011130\n",
      "                     0        0       1       0                0.007621\n",
      "dtype: float64\n",
      "toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
      "0      0             0        0       0       0                0.897972\n",
      "1      0             0        0       0       0                0.035898\n",
      "                     1        0       1       0                0.024341\n",
      "                                      0       0                0.010679\n",
      "                     0        0       1       0                0.007596\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts(normalize=True).head())\n",
    "print(y_test.value_counts(normalize=True).head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   24.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_scores: [0.665596   0.6533872  0.65558413 0.65649536 0.65011609]\n",
      "average f1_score: 0.6562357575288501\n",
      "alpha: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   25.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_scores: [0.67091256 0.65440686 0.65723065 0.66116602 0.65353902]\n",
      "average f1_score: 0.6594510233374304\n",
      "alpha: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   24.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_scores: [0.67183606 0.65665278 0.65904582 0.66457622 0.65618933]\n",
      "average f1_score: 0.6616600416763341\n",
      "alpha: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   23.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_scores: [0.6722973  0.65754503 0.65955197 0.66585389 0.65570382]\n",
      "average f1_score: 0.6621903999521076\n",
      "alpha: 0.3\n",
      "f1_scores: [0.67264916 0.6580052  0.65982806 0.66590389 0.65800287]\n",
      "average f1_score: 0.6628778352506939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   24.7s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for alpha_index in np.array([0.1, 0.15, 0.2, 0.25, 0.3]):\n",
    "    \n",
    "    print('-- alpha: {} --'.format(alpha_index))\n",
    "    OVR_NB_pipeline = Pipeline([\n",
    "                    # ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                    ('Vectorizer', CountVectorizer(stop_words='english')),\n",
    "                    ('MultiNB', OneVsRestClassifier(MultinomialNB(alpha=alpha_index) )),\n",
    "                ])\n",
    "\n",
    "    cv = cross_val_score(OVR_NB_pipeline, X_train, y_train, cv=kf, scoring ='f1_micro', verbose=0)\n",
    "    print('f1_scores: {}'.format(cv))\n",
    "    print('average f1_score: {}'.format(np.mean(cv)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha_f1_macro = {'alpha': [0.0001, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 1.2], \n",
    "                'f1_macro': [0.463, 0.515, 0.511, 0.505, 0.497, 0.493, 0.481, 0.474, 0.462, 0.455, 0.447, 0.419]}\n",
    "alpha_f1_micro = {'alpha': [0.0001, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.6], \n",
    "                'f1_micro': [0.600, 0.656, 0.659, 0.662, 0.662, 0.663, 0.659, 0.650]}\n",
    "\n",
    "plt.plot(alpha_f1_macro['alpha'], alpha_f1_macro['f1_macro'], label='f1_macro')\n",
    "plt.plot(alpha_f1_micro['alpha'], alpha_f1_micro['f1_micro'], label='f1_micro')\n",
    "\n",
    "plt.xlabel('alpha parameter')\n",
    "plt.ylabel('f1_scores')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = 0.1\n",
    "OVR_NB_pipeline = Pipeline([\n",
    "                ('Vectorizer', CountVectorizer(stop_words='english')),\n",
    "                ('MultiNB', OneVsRestClassifier(MultinomialNB(alpha=best_alpha) ))    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating classification models\n",
    "\n",
    "models = {\"Logistic Regression\": LogisticRegression(), \n",
    "          \"KNN\": KNeighborsClassifier(), \n",
    "          \"DecisionTree\": DecisionTreeClassifier(),\n",
    "          \"LinearSVC\": LinearSVC()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'professor marvin h mills is a self published crank his book is printed by iuniverse a vanity publishing company mills also believes that the mosques in spain were built by phoenicians aided by survivors from atlantis we learn of the piri reis map that it lead ivar zapp and george erikson in atlantis in america to assert that an awareness of antartica was known to an advanced civilization at the end of the ice age and yes the published version of this book really does spell the second word of that sentence with an a mills is not a reliable source he is self published and his views are fringe'"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "X_train = train_df['cleaner_text']\n",
    "y = train_labels\n",
    "\n",
    "X = CountVectorizer(stop_words='english').fit_transform(train_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             cleaned_text  toxic  \\\n",
      "159281  lol you are gay you will never know how good i...      1   \n",
      "159336  oh fuck off the pansy jew would just whine abo...      1   \n",
      "159400  shalom semite get the fuck out of here i will ...      1   \n",
      "159449                            i think he is a gay fag      1   \n",
      "159494  our previous conversation you fucking shit eat...      1   \n",
      "\n",
      "        severe_toxic  obscene  threat  insult  identity_hate  \\\n",
      "159281             1        1       0       1              1   \n",
      "159336             0        1       0       1              1   \n",
      "159400             1        1       1       1              1   \n",
      "159449             0        0       0       0              1   \n",
      "159494             0        1       0       1              1   \n",
      "\n",
      "                                             cleaner_text  \n",
      "159281         lol gay never know good feel fuck woman as  \n",
      "159336  oh fuck pansy jew would whine bnai brith beat ...  \n",
      "159400  shalom semite get fuck kill son bitch leave wi...  \n",
      "159449                                      think gay fag  \n",
      "159494  previous conversation fucking shit eating libe...  \n"
     ]
    }
   ],
   "source": [
    "fltr = train_df[train_df['identity_hate'] == 1] \n",
    "print(fltr.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing toxic label\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_neg_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.868228</td>\n",
       "      <td>0.867674</td>\n",
       "      <td>0.905282</td>\n",
       "      <td>0.819118</td>\n",
       "      <td>0.860048</td>\n",
       "      <td>-0.837440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861485</td>\n",
       "      <td>0.902232</td>\n",
       "      <td>0.813280</td>\n",
       "      <td>0.855450</td>\n",
       "      <td>-0.937038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.875764</td>\n",
       "      <td>0.875314</td>\n",
       "      <td>0.899823</td>\n",
       "      <td>0.841866</td>\n",
       "      <td>0.869881</td>\n",
       "      <td>-0.817515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.875127</td>\n",
       "      <td>0.875069</td>\n",
       "      <td>0.908082</td>\n",
       "      <td>0.834353</td>\n",
       "      <td>0.869658</td>\n",
       "      <td>-0.803532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.871868</td>\n",
       "      <td>0.872533</td>\n",
       "      <td>0.913701</td>\n",
       "      <td>0.825231</td>\n",
       "      <td>0.867216</td>\n",
       "      <td>-0.790010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_accuracy  test_balanced_accuracy  test_precision  test_recall  \\\n",
       "0       0.868228                0.867674        0.905282     0.819118   \n",
       "1       0.860896                0.861485        0.902232     0.813280   \n",
       "2       0.875764                0.875314        0.899823     0.841866   \n",
       "3       0.875127                0.875069        0.908082     0.834353   \n",
       "4       0.871868                0.872533        0.913701     0.825231   \n",
       "\n",
       "    test_f1  test_neg_log_loss  \n",
       "0  0.860048          -0.837440  \n",
       "1  0.855450          -0.937038  \n",
       "2  0.869881          -0.817515  \n",
       "3  0.869658          -0.803532  \n",
       "4  0.867216          -0.790010  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing severe_toxic label\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_neg_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.937751</td>\n",
       "      <td>0.937758</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.939335</td>\n",
       "      <td>-0.490504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.945802</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.946721</td>\n",
       "      <td>0.944785</td>\n",
       "      <td>-0.402086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.923695</td>\n",
       "      <td>0.923694</td>\n",
       "      <td>0.924000</td>\n",
       "      <td>0.924000</td>\n",
       "      <td>0.924000</td>\n",
       "      <td>-0.560068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.927894</td>\n",
       "      <td>0.913386</td>\n",
       "      <td>0.943089</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>-0.323998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.933735</td>\n",
       "      <td>0.933735</td>\n",
       "      <td>0.925197</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>0.934394</td>\n",
       "      <td>-0.395155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_accuracy  test_balanced_accuracy  test_precision  test_recall  \\\n",
       "0       0.937751                0.937758        0.941176     0.937500   \n",
       "1       0.945783                0.945802        0.942857     0.946721   \n",
       "2       0.923695                0.923694        0.924000     0.924000   \n",
       "3       0.927711                0.927894        0.913386     0.943089   \n",
       "4       0.933735                0.933735        0.925197     0.943775   \n",
       "\n",
       "    test_f1  test_neg_log_loss  \n",
       "0  0.939335          -0.490504  \n",
       "1  0.944785          -0.402086  \n",
       "2  0.924000          -0.560068  \n",
       "3  0.928000          -0.323998  \n",
       "4  0.934394          -0.395155  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing obscene label\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_neg_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.895594</td>\n",
       "      <td>0.895582</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.862222</td>\n",
       "      <td>0.891954</td>\n",
       "      <td>-0.817217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.900407</td>\n",
       "      <td>0.900732</td>\n",
       "      <td>0.924923</td>\n",
       "      <td>0.874177</td>\n",
       "      <td>0.898834</td>\n",
       "      <td>-0.864162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.900370</td>\n",
       "      <td>0.899509</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.874233</td>\n",
       "      <td>0.894468</td>\n",
       "      <td>-0.707633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.904074</td>\n",
       "      <td>0.904011</td>\n",
       "      <td>0.921645</td>\n",
       "      <td>0.882615</td>\n",
       "      <td>0.901708</td>\n",
       "      <td>-0.737875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.892593</td>\n",
       "      <td>0.893066</td>\n",
       "      <td>0.912519</td>\n",
       "      <td>0.874277</td>\n",
       "      <td>0.892989</td>\n",
       "      <td>-0.740492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_accuracy  test_balanced_accuracy  test_precision  test_recall  \\\n",
       "0       0.895594                0.895582        0.923810     0.862222   \n",
       "1       0.900407                0.900732        0.924923     0.874177   \n",
       "2       0.900370                0.899509        0.915663     0.874233   \n",
       "3       0.904074                0.904011        0.921645     0.882615   \n",
       "4       0.892593                0.893066        0.912519     0.874277   \n",
       "\n",
       "    test_f1  test_neg_log_loss  \n",
       "0  0.891954          -0.817217  \n",
       "1  0.898834          -0.864162  \n",
       "2  0.894468          -0.707633  \n",
       "3  0.901708          -0.737875  \n",
       "4  0.892989          -0.740492  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing threat label\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_neg_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.897003</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>-0.607587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.922840</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>-0.299312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.902654</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.917808</td>\n",
       "      <td>0.899329</td>\n",
       "      <td>-0.726918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.915033</td>\n",
       "      <td>0.914706</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>-0.648640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.895613</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>-0.422226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_accuracy  test_balanced_accuracy  test_precision  test_recall  \\\n",
       "0       0.895425                0.897003        0.860759     0.931507   \n",
       "1       0.921569                0.922840        0.894737     0.944444   \n",
       "2       0.901961                0.902654        0.881579     0.917808   \n",
       "3       0.915033                0.914706        0.928571     0.917647   \n",
       "4       0.894737                0.895613        0.920000     0.873418   \n",
       "\n",
       "    test_f1  test_neg_log_loss  \n",
       "0  0.894737          -0.607587  \n",
       "1  0.918919          -0.299312  \n",
       "2  0.899329          -0.726918  \n",
       "3  0.923077          -0.648640  \n",
       "4  0.896104          -0.422226  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing insult label\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_neg_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.893397</td>\n",
       "      <td>0.893065</td>\n",
       "      <td>0.911168</td>\n",
       "      <td>0.868548</td>\n",
       "      <td>0.889348</td>\n",
       "      <td>-0.650839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.871468</td>\n",
       "      <td>0.870480</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.819805</td>\n",
       "      <td>0.862143</td>\n",
       "      <td>-0.941718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.891365</td>\n",
       "      <td>0.891176</td>\n",
       "      <td>0.927448</td>\n",
       "      <td>0.848122</td>\n",
       "      <td>0.886013</td>\n",
       "      <td>-0.771260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.884600</td>\n",
       "      <td>0.885083</td>\n",
       "      <td>0.924610</td>\n",
       "      <td>0.840157</td>\n",
       "      <td>0.880363</td>\n",
       "      <td>-0.833813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.886988</td>\n",
       "      <td>0.888266</td>\n",
       "      <td>0.932874</td>\n",
       "      <td>0.840310</td>\n",
       "      <td>0.884176</td>\n",
       "      <td>-0.842813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_accuracy  test_balanced_accuracy  test_precision  test_recall  \\\n",
       "0       0.893397                0.893065        0.911168     0.868548   \n",
       "1       0.871468                0.870480        0.909091     0.819805   \n",
       "2       0.891365                0.891176        0.927448     0.848122   \n",
       "3       0.884600                0.885083        0.924610     0.840157   \n",
       "4       0.886988                0.888266        0.932874     0.840310   \n",
       "\n",
       "    test_f1  test_neg_log_loss  \n",
       "0  0.889348          -0.650839  \n",
       "1  0.862143          -0.941718  \n",
       "2  0.886013          -0.771260  \n",
       "3  0.880363          -0.833813  \n",
       "4  0.884176          -0.842813  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing identity_hate label\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_neg_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.885210</td>\n",
       "      <td>0.884822</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.875576</td>\n",
       "      <td>0.879630</td>\n",
       "      <td>-0.622492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.902870</td>\n",
       "      <td>0.902865</td>\n",
       "      <td>0.903509</td>\n",
       "      <td>0.903509</td>\n",
       "      <td>0.903509</td>\n",
       "      <td>-0.569741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.913717</td>\n",
       "      <td>0.913627</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.911565</td>\n",
       "      <td>-0.556544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.882743</td>\n",
       "      <td>0.883323</td>\n",
       "      <td>0.908257</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.881960</td>\n",
       "      <td>-0.719595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.896018</td>\n",
       "      <td>0.896416</td>\n",
       "      <td>0.917808</td>\n",
       "      <td>0.873913</td>\n",
       "      <td>0.895323</td>\n",
       "      <td>-0.673827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_accuracy  test_balanced_accuracy  test_precision  test_recall  \\\n",
       "0       0.885210                0.884822        0.883721     0.875576   \n",
       "1       0.902870                0.902865        0.903509     0.903509   \n",
       "2       0.913717                0.913627        0.930556     0.893333   \n",
       "3       0.882743                0.883323        0.908257     0.857143   \n",
       "4       0.896018                0.896416        0.917808     0.873913   \n",
       "\n",
       "    test_f1  test_neg_log_loss  \n",
       "0  0.879630          -0.622492  \n",
       "1  0.903509          -0.569741  \n",
       "2  0.911565          -0.556544  \n",
       "3  0.881960          -0.719595  \n",
       "4  0.895323          -0.673827  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, cross_validate\n",
    "\n",
    "smote = SMOTE()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "MultiNB = MultinomialNB() # NB takes ~10s to train all labels\n",
    "LR = LogisticRegression()  # LR takes > 2 min to train all labels\n",
    "\n",
    "cv_all = pd.DataFrame()\n",
    "\n",
    "for label in LABELS:\n",
    "    \n",
    "    X_smote, y_smote = smote.fit_resample(X_train, y_train[label])\n",
    "    X_rus, y_rus = rus.fit_resample(X_train, y_train[label])\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    score_evals = ['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1', 'neg_log_loss']\n",
    "    cv = cross_validate(NB, X_rus, y_rus, cv=kf, scoring = score_evals, return_estimator=True)\n",
    "\n",
    "    cv_df = pd.DataFrame(cv)\n",
    "    cv_df.drop(['fit_time', 'score_time', 'estimator'], axis = 1, inplace = True) \n",
    "    \n",
    "    print('Processing {} label'.format(label))\n",
    "    display(cv_df)\n",
    "    \n",
    "    cv_mean = cv_df.mean()\n",
    "    cv_all = pd.concat([cv_all, cv_mean], axis=1)\n",
    "\n",
    "cv_all.columns = LABELS  # set the column names\n",
    "cv_all.index = score_evals # set the index names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.870377</td>\n",
       "      <td>0.933735</td>\n",
       "      <td>0.898608</td>\n",
       "      <td>0.905745</td>\n",
       "      <td>0.885564</td>\n",
       "      <td>0.896111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.870415</td>\n",
       "      <td>0.933776</td>\n",
       "      <td>0.898580</td>\n",
       "      <td>0.906563</td>\n",
       "      <td>0.885614</td>\n",
       "      <td>0.896211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.905824</td>\n",
       "      <td>0.929323</td>\n",
       "      <td>0.919712</td>\n",
       "      <td>0.897129</td>\n",
       "      <td>0.921038</td>\n",
       "      <td>0.908770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.826770</td>\n",
       "      <td>0.939017</td>\n",
       "      <td>0.873505</td>\n",
       "      <td>0.916965</td>\n",
       "      <td>0.843389</td>\n",
       "      <td>0.880695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.864450</td>\n",
       "      <td>0.934103</td>\n",
       "      <td>0.895991</td>\n",
       "      <td>0.906433</td>\n",
       "      <td>0.880408</td>\n",
       "      <td>0.894397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg_log_loss</th>\n",
       "      <td>-0.837107</td>\n",
       "      <td>-0.434362</td>\n",
       "      <td>-0.773476</td>\n",
       "      <td>-0.540937</td>\n",
       "      <td>-0.808088</td>\n",
       "      <td>-0.628440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      toxic  severe_toxic   obscene    threat    insult  \\\n",
       "accuracy           0.870377      0.933735  0.898608  0.905745  0.885564   \n",
       "balanced_accuracy  0.870415      0.933776  0.898580  0.906563  0.885614   \n",
       "precision          0.905824      0.929323  0.919712  0.897129  0.921038   \n",
       "recall             0.826770      0.939017  0.873505  0.916965  0.843389   \n",
       "f1                 0.864450      0.934103  0.895991  0.906433  0.880408   \n",
       "neg_log_loss      -0.837107     -0.434362 -0.773476 -0.540937 -0.808088   \n",
       "\n",
       "                   identity_hate  \n",
       "accuracy                0.896111  \n",
       "balanced_accuracy       0.896211  \n",
       "precision               0.908770  \n",
       "recall                  0.880695  \n",
       "f1                      0.894397  \n",
       "neg_log_loss           -0.628440  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(cv_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy             0.911811\n",
       "balanced_accuracy    0.911623\n",
       "precision            0.939029\n",
       "recall               0.881478\n",
       "f1                   0.909142\n",
       "neg_log_loss        -0.280026\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_all.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_all.to_csv('scores_LR_rus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index(['test_balanced_accuracy', 'test_precision', 'test_recall', 'test_f1',\n",
      "       'test_neg_log_loss'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(type(cv_df.mean()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properly evaluate with testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Multinomial Naive Bayes --\n",
      "Original\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.81, 0.65, 0.63, 0.64)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, cross_validate\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "smote = SMOTE()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "# model = MultinomialNB() # NB takes ~10s to train all labels\n",
    "model = LogisticRegression()  # LR takes > 2 min to train all labels\n",
    "\n",
    "label = 'obscene'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y[label], test_size=0.2)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "def model_train_evaluate(model, X_train, y_train, X_test, y_test, dec=2, verbose=False):\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "\n",
    "    # print('Processing {} label'.format(label))\n",
    "    # print(classification_report(y_test, pred, output_dict=False))\n",
    "    bal_acc = np.round(balanced_accuracy_score(y_test, pred), dec)\n",
    "    prec, rec, f1 = np.round(precision_recall_fscore_support(y_test, pred, average='binary', pos_label=1)[:3] , dec)\n",
    "    if verbose:\n",
    "        print('bal_acc: {}, precision: {}, recall: {}, f1: {}'.format(bal_acc, prec, rec, f1) )  \n",
    "    \n",
    "    return bal_acc, prec, rec, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n",
      "C:\\Users\\Feng\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\3616699757.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scores = scores.append({'label': label,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>imbalance_ratio</th>\n",
       "      <th>clf_model</th>\n",
       "      <th>train_split</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.095</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.095</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.095</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.095</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.095</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.095</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.053</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.053</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.053</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.053</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.053</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.053</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.050</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.050</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.050</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.050</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.050</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.050</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.010</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.010</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.010</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.010</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.010</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.010</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.009</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.009</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.009</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.009</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.009</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.009</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.003</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.003</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.003</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.003</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.003</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.003</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label  imbalance_ratio           clf_model train_split  \\\n",
       "0          toxic            0.095       MultinomialNB    Original   \n",
       "1          toxic            0.095  LogisticRegression    Original   \n",
       "2          toxic            0.095       MultinomialNB         RUS   \n",
       "3          toxic            0.095  LogisticRegression         RUS   \n",
       "4          toxic            0.095       MultinomialNB       SMOTE   \n",
       "5          toxic            0.095  LogisticRegression       SMOTE   \n",
       "0        obscene            0.053       MultinomialNB    Original   \n",
       "1        obscene            0.053  LogisticRegression    Original   \n",
       "2        obscene            0.053       MultinomialNB         RUS   \n",
       "3        obscene            0.053  LogisticRegression         RUS   \n",
       "4        obscene            0.053       MultinomialNB       SMOTE   \n",
       "5        obscene            0.053  LogisticRegression       SMOTE   \n",
       "0         insult            0.050       MultinomialNB    Original   \n",
       "1         insult            0.050  LogisticRegression    Original   \n",
       "2         insult            0.050       MultinomialNB         RUS   \n",
       "3         insult            0.050  LogisticRegression         RUS   \n",
       "4         insult            0.050       MultinomialNB       SMOTE   \n",
       "5         insult            0.050  LogisticRegression       SMOTE   \n",
       "0   severe_toxic            0.010       MultinomialNB    Original   \n",
       "1   severe_toxic            0.010  LogisticRegression    Original   \n",
       "2   severe_toxic            0.010       MultinomialNB         RUS   \n",
       "3   severe_toxic            0.010  LogisticRegression         RUS   \n",
       "4   severe_toxic            0.010       MultinomialNB       SMOTE   \n",
       "5   severe_toxic            0.010  LogisticRegression       SMOTE   \n",
       "0  identity_hate            0.009       MultinomialNB    Original   \n",
       "1  identity_hate            0.009  LogisticRegression    Original   \n",
       "2  identity_hate            0.009       MultinomialNB         RUS   \n",
       "3  identity_hate            0.009  LogisticRegression         RUS   \n",
       "4  identity_hate            0.009       MultinomialNB       SMOTE   \n",
       "5  identity_hate            0.009  LogisticRegression       SMOTE   \n",
       "0         threat            0.003       MultinomialNB    Original   \n",
       "1         threat            0.003  LogisticRegression    Original   \n",
       "2         threat            0.003       MultinomialNB         RUS   \n",
       "3         threat            0.003  LogisticRegression         RUS   \n",
       "4         threat            0.003       MultinomialNB       SMOTE   \n",
       "5         threat            0.003  LogisticRegression       SMOTE   \n",
       "\n",
       "   balanced_accuracy  precision  recall  f1_score  \n",
       "0               0.79       0.71    0.61      0.66  \n",
       "1               0.82       0.83    0.66      0.74  \n",
       "2               0.87       0.51    0.84      0.63  \n",
       "3               0.89       0.55    0.87      0.67  \n",
       "4               0.80       0.66    0.64      0.65  \n",
       "5               0.85       0.45    0.80      0.57  \n",
       "0               0.79       0.64    0.60      0.62  \n",
       "1               0.83       0.86    0.66      0.74  \n",
       "2               0.89       0.38    0.86      0.52  \n",
       "3               0.92       0.57    0.88      0.69  \n",
       "4               0.82       0.58    0.66      0.62  \n",
       "5               0.86       0.38    0.80      0.51  \n",
       "0               0.75       0.56    0.51      0.54  \n",
       "1               0.74       0.76    0.50      0.60  \n",
       "2               0.89       0.38    0.85      0.52  \n",
       "3               0.91       0.42    0.89      0.57  \n",
       "4               0.79       0.53    0.60      0.56  \n",
       "5               0.81       0.28    0.71      0.41  \n",
       "0               0.70       0.29    0.40      0.34  \n",
       "1               0.60       0.44    0.20      0.28  \n",
       "2               0.93       0.13    0.92      0.23  \n",
       "3               0.94       0.20    0.92      0.33  \n",
       "4               0.78       0.29    0.58      0.38  \n",
       "5               0.81       0.12    0.68      0.20  \n",
       "0               0.59       0.20    0.20      0.20  \n",
       "1               0.61       0.51    0.22      0.30  \n",
       "2               0.92       0.09    0.92      0.17  \n",
       "3               0.91       0.11    0.89      0.19  \n",
       "4               0.72       0.18    0.46      0.26  \n",
       "5               0.76       0.08    0.58      0.13  \n",
       "0               0.51       0.03    0.03      0.03  \n",
       "1               0.61       0.38    0.23      0.29  \n",
       "2               0.87       0.03    0.84      0.05  \n",
       "3               0.89       0.06    0.83      0.10  \n",
       "4               0.63       0.07    0.27      0.11  \n",
       "5               0.67       0.03    0.39      0.06  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_evaluate_all_labels(models, X, y, label='toxic', verbose=False):\n",
    "    '''\n",
    "    models: dict, for iterating through classifier models\n",
    "    X, y: pd.DataFrame, array-like\n",
    "    label: string that matches the columns of data\n",
    "    verbose: bool, for optional print outs\n",
    "    '''\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y[label], test_size=0.2) # Original split\n",
    "    X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train) # Random Under Sampling (RUS)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train) #Synthetic Oversampling (SMOTE)\n",
    "    \n",
    "    n_0, n_1 = y_train.value_counts()\n",
    "    imbalance_ratio = np.round(n_1/(n_0 + n_1), 3)\n",
    "    \n",
    "    train_sets = {'Original': [X_train, y_train], \n",
    "                    'RUS': [X_train_rus, y_train_rus], \n",
    "                    'SMOTE': [X_train_smote, y_train_smote]}\n",
    "    \n",
    "    scores = pd.DataFrame()  # initialize empty DF to store everything\n",
    "    \n",
    "    # iterate through the different training sets, must be in dictionary format\n",
    "    for train_split, train_data in train_sets.items():  \n",
    "        X_input, y_input = train_data\n",
    "        \n",
    "        # iterate through the classifier models, must be in dictionary format\n",
    "        for model_name, model in models.items(): \n",
    "            \n",
    "            bal_acc, prec, rec, f1 = model_train_evaluate(model, X_input, y_input, X_test, y_test, verbose= verbose)\n",
    "            scores = scores.append({'label': label,\n",
    "                                    'imbalance_ratio': imbalance_ratio, \n",
    "                                    'clf_model': model_name,\n",
    "                                    'train_split': train_split,\n",
    "                                    'balanced_accuracy': bal_acc,\n",
    "                                    'precision': prec,\n",
    "                                    'recall': rec,\n",
    "                                    'f1_score': f1}, ignore_index=True)\n",
    "            \n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[203], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m LABELS \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mtoxic\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mobscene\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minsult\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msevere_toxic\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39midentity_hate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mthreat\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m LABELS:\n\u001b[1;32m---> 12\u001b[0m     scores \u001b[39m=\u001b[39m train_evaluate_all_labels(models, X, y, label\u001b[39m=\u001b[39;49mlabel, verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     13\u001b[0m     \u001b[39m# print(scores)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     all_scores2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([all_scores, scores], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[193], line 22\u001b[0m, in \u001b[0;36mtrain_evaluate_all_labels\u001b[1;34m(models, X, y, label, verbose)\u001b[0m\n\u001b[0;32m     17\u001b[0m     X_input, y_input \u001b[39m=\u001b[39m train_data\n\u001b[0;32m     19\u001b[0m     \u001b[39mfor\u001b[39;00m model_name, model \u001b[39min\u001b[39;00m models\u001b[39m.\u001b[39mitems():\n\u001b[1;32m---> 22\u001b[0m         bal_acc, prec, rec, f1 \u001b[39m=\u001b[39m model_train_evaluate(model, X_input, y_input, X_test, y_test, verbose\u001b[39m=\u001b[39;49m verbose)\n\u001b[0;32m     23\u001b[0m         scores \u001b[39m=\u001b[39m scores\u001b[39m.\u001b[39mappend({\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: label,\n\u001b[0;32m     24\u001b[0m                                 \u001b[39m'\u001b[39m\u001b[39mimbalance_ratio\u001b[39m\u001b[39m'\u001b[39m: imbalance_ratio, \n\u001b[0;32m     25\u001b[0m                                 \u001b[39m'\u001b[39m\u001b[39mclf_model\u001b[39m\u001b[39m'\u001b[39m: model_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m                                 \u001b[39m'\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m'\u001b[39m: rec,\n\u001b[0;32m     30\u001b[0m                                 \u001b[39m'\u001b[39m\u001b[39mf1_score\u001b[39m\u001b[39m'\u001b[39m: f1}, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     32\u001b[0m \u001b[39mreturn\u001b[39;00m scores\n",
      "Cell \u001b[1;32mIn[177], line 21\u001b[0m, in \u001b[0;36mmodel_train_evaluate\u001b[1;34m(model, X_train, y_train, X_test, y_test, dec, verbose)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel_train_evaluate\u001b[39m(model, X_train, y_train, X_test, y_test, dec\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 21\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     22\u001b[0m     pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     24\u001b[0m     \u001b[39m# print('Processing {} label'.format(label))\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     \u001b[39m# print(classification_report(y_test, pred, output_dict=False))\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\naive_bayes.py:267\u001b[0m, in \u001b[0;36mGaussianNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m    266\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(y\u001b[39m=\u001b[39my)\n\u001b[1;32m--> 267\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partial_fit(\n\u001b[0;32m    268\u001b[0m     X, y, np\u001b[39m.\u001b[39;49munique(y), _refit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[0;32m    269\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\naive_bayes.py:426\u001b[0m, in \u001b[0;36mGaussianNB._partial_fit\u001b[1;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    425\u001b[0m first_call \u001b[39m=\u001b[39m _check_partial_fit_first_call(\u001b[39mself\u001b[39m, classes)\n\u001b[1;32m--> 426\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, y, reset\u001b[39m=\u001b[39;49mfirst_call)\n\u001b[0;32m    427\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    428\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:554\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    552\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    553\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 554\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    555\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    557\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:1104\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1099\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1100\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1101\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1102\u001b[0m     )\n\u001b[1;32m-> 1104\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1105\u001b[0m     X,\n\u001b[0;32m   1106\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1107\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1108\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1109\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1110\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1111\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1112\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1113\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1114\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1115\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1116\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1117\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1118\u001b[0m )\n\u001b[0;32m   1120\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1122\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:843\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[39mif\u001b[39;00m sp\u001b[39m.\u001b[39missparse(array):\n\u001b[0;32m    842\u001b[0m     _ensure_no_complex_data(array)\n\u001b[1;32m--> 843\u001b[0m     array \u001b[39m=\u001b[39m _ensure_sparse_format(\n\u001b[0;32m    844\u001b[0m         array,\n\u001b[0;32m    845\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m    846\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    847\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    848\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    849\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m    850\u001b[0m         estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    851\u001b[0m         input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    852\u001b[0m     )\n\u001b[0;32m    853\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    854\u001b[0m     \u001b[39m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[39m# to an error. This is needed because specifying a non complex\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# dtype to the function converts complex to real dtype,\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39m# thereby passing the test made in the lines following the scope\u001b[39;00m\n\u001b[0;32m    858\u001b[0m     \u001b[39m# of warnings context manager.\u001b[39;00m\n\u001b[0;32m    859\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:522\u001b[0m, in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    519\u001b[0m _check_large_sparse(spmatrix, accept_large_sparse)\n\u001b[0;32m    521\u001b[0m \u001b[39mif\u001b[39;00m accept_sparse \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m--> 522\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    523\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA sparse matrix was passed, but dense \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    524\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdata is required. Use X.toarray() to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mconvert to a dense numpy array.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m     )\n\u001b[0;32m    527\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(accept_sparse, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m    528\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(accept_sparse) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "models = {'MultinomialNB': MultinomialNB(), 'LogisticRegression': LogisticRegression()}\n",
    "all_scores= pd.DataFrame()\n",
    "LABELS = ['toxic', 'obscene', 'insult', 'severe_toxic', 'identity_hate', 'threat']\n",
    "\n",
    "for label in LABELS:\n",
    "    scores = train_evaluate_all_labels(models, X, y, label=label, verbose=False)\n",
    "    # print(scores)\n",
    "    all_scores = pd.concat([all_scores, scores], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\462376751.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  display(all_scores.groupby(['label']).mean().sort_values(by='imbalance_ratio'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imbalance_ratio</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>threat</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.696667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.431667</td>\n",
       "      <td>0.106667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identity_hate</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe_toxic</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.293333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insult</th>\n",
       "      <td>0.050</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.488333</td>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obscene</th>\n",
       "      <td>0.053</td>\n",
       "      <td>0.851667</td>\n",
       "      <td>0.568333</td>\n",
       "      <td>0.743333</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>0.095</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>0.618333</td>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.653333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               imbalance_ratio  balanced_accuracy  precision    recall  \\\n",
       "label                                                                    \n",
       "threat                   0.003           0.696667   0.100000  0.431667   \n",
       "identity_hate            0.009           0.751667   0.195000  0.545000   \n",
       "severe_toxic             0.010           0.793333   0.245000  0.616667   \n",
       "insult                   0.050           0.815000   0.488333  0.676667   \n",
       "obscene                  0.053           0.851667   0.568333  0.743333   \n",
       "toxic                    0.095           0.836667   0.618333  0.736667   \n",
       "\n",
       "               f1_score  \n",
       "label                    \n",
       "threat         0.106667  \n",
       "identity_hate  0.208333  \n",
       "severe_toxic   0.293333  \n",
       "insult         0.533333  \n",
       "obscene        0.616667  \n",
       "toxic          0.653333  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\462376751.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  display(all_scores.groupby(['clf_model']).mean())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imbalance_ratio</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.801667</td>\n",
       "      <td>0.390556</td>\n",
       "      <td>0.650556</td>\n",
       "      <td>0.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.347778</td>\n",
       "      <td>0.599444</td>\n",
       "      <td>0.393889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    imbalance_ratio  balanced_accuracy  precision    recall  \\\n",
       "clf_model                                                                     \n",
       "LogisticRegression         0.036667           0.801667   0.390556  0.650556   \n",
       "MultinomialNB              0.036667           0.780000   0.347778  0.599444   \n",
       "\n",
       "                    f1_score  \n",
       "clf_model                     \n",
       "LogisticRegression  0.410000  \n",
       "MultinomialNB       0.393889  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feng\\AppData\\Local\\Temp\\ipykernel_28824\\462376751.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  display(all_scores.groupby(['train_split']).mean())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imbalance_ratio</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Original</th>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.6950</td>\n",
       "      <td>0.517500</td>\n",
       "      <td>0.401667</td>\n",
       "      <td>0.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RUS</th>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.9025</td>\n",
       "      <td>0.285833</td>\n",
       "      <td>0.875833</td>\n",
       "      <td>0.389167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE</th>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.304167</td>\n",
       "      <td>0.597500</td>\n",
       "      <td>0.371667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             imbalance_ratio  balanced_accuracy  precision    recall  f1_score\n",
       "train_split                                                                   \n",
       "Original            0.036667             0.6950   0.517500  0.401667  0.445000\n",
       "RUS                 0.036667             0.9025   0.285833  0.875833  0.389167\n",
       "SMOTE               0.036667             0.7750   0.304167  0.597500  0.371667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(all_scores)\n",
    "display(all_scores.groupby(['label']).mean().sort_values(by='imbalance_ratio'))\n",
    "display(all_scores.groupby(['clf_model']).mean())\n",
    "display(all_scores.groupby(['train_split']).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "tags": [
     "grid search df"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>imbalance_ratio</th>\n",
       "      <th>clf_model</th>\n",
       "      <th>train_split</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.010</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.010</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.009</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.053</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.009</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.050</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.053</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.003</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.050</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.095</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.095</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.003</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.053</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.095</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.053</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.053</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.095</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.050</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.010</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.095</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.050</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.053</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.095</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.010</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.009</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.050</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.050</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.009</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.010</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.003</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.003</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.009</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.003</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.010</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.009</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.003</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label  imbalance_ratio           clf_model train_split  \\\n",
       "3   severe_toxic            0.010  LogisticRegression         RUS   \n",
       "2   severe_toxic            0.010       MultinomialNB         RUS   \n",
       "2  identity_hate            0.009       MultinomialNB         RUS   \n",
       "3        obscene            0.053  LogisticRegression         RUS   \n",
       "3  identity_hate            0.009  LogisticRegression         RUS   \n",
       "3         insult            0.050  LogisticRegression         RUS   \n",
       "2        obscene            0.053       MultinomialNB         RUS   \n",
       "3         threat            0.003  LogisticRegression         RUS   \n",
       "2         insult            0.050       MultinomialNB         RUS   \n",
       "3          toxic            0.095  LogisticRegression         RUS   \n",
       "2          toxic            0.095       MultinomialNB         RUS   \n",
       "2         threat            0.003       MultinomialNB         RUS   \n",
       "5        obscene            0.053  LogisticRegression       SMOTE   \n",
       "5          toxic            0.095  LogisticRegression       SMOTE   \n",
       "1        obscene            0.053  LogisticRegression    Original   \n",
       "4        obscene            0.053       MultinomialNB       SMOTE   \n",
       "1          toxic            0.095  LogisticRegression    Original   \n",
       "5         insult            0.050  LogisticRegression       SMOTE   \n",
       "5   severe_toxic            0.010  LogisticRegression       SMOTE   \n",
       "4          toxic            0.095       MultinomialNB       SMOTE   \n",
       "4         insult            0.050       MultinomialNB       SMOTE   \n",
       "0        obscene            0.053       MultinomialNB    Original   \n",
       "0          toxic            0.095       MultinomialNB    Original   \n",
       "4   severe_toxic            0.010       MultinomialNB       SMOTE   \n",
       "5  identity_hate            0.009  LogisticRegression       SMOTE   \n",
       "0         insult            0.050       MultinomialNB    Original   \n",
       "1         insult            0.050  LogisticRegression    Original   \n",
       "4  identity_hate            0.009       MultinomialNB       SMOTE   \n",
       "0   severe_toxic            0.010       MultinomialNB    Original   \n",
       "5         threat            0.003  LogisticRegression       SMOTE   \n",
       "4         threat            0.003       MultinomialNB       SMOTE   \n",
       "1  identity_hate            0.009  LogisticRegression    Original   \n",
       "1         threat            0.003  LogisticRegression    Original   \n",
       "1   severe_toxic            0.010  LogisticRegression    Original   \n",
       "0  identity_hate            0.009       MultinomialNB    Original   \n",
       "0         threat            0.003       MultinomialNB    Original   \n",
       "\n",
       "   balanced_accuracy  precision  recall  f1_score  \n",
       "3               0.94       0.20    0.92      0.33  \n",
       "2               0.93       0.13    0.92      0.23  \n",
       "2               0.92       0.09    0.92      0.17  \n",
       "3               0.92       0.57    0.88      0.69  \n",
       "3               0.91       0.11    0.89      0.19  \n",
       "3               0.91       0.42    0.89      0.57  \n",
       "2               0.89       0.38    0.86      0.52  \n",
       "3               0.89       0.06    0.83      0.10  \n",
       "2               0.89       0.38    0.85      0.52  \n",
       "3               0.89       0.55    0.87      0.67  \n",
       "2               0.87       0.51    0.84      0.63  \n",
       "2               0.87       0.03    0.84      0.05  \n",
       "5               0.86       0.38    0.80      0.51  \n",
       "5               0.85       0.45    0.80      0.57  \n",
       "1               0.83       0.86    0.66      0.74  \n",
       "4               0.82       0.58    0.66      0.62  \n",
       "1               0.82       0.83    0.66      0.74  \n",
       "5               0.81       0.28    0.71      0.41  \n",
       "5               0.81       0.12    0.68      0.20  \n",
       "4               0.80       0.66    0.64      0.65  \n",
       "4               0.79       0.53    0.60      0.56  \n",
       "0               0.79       0.64    0.60      0.62  \n",
       "0               0.79       0.71    0.61      0.66  \n",
       "4               0.78       0.29    0.58      0.38  \n",
       "5               0.76       0.08    0.58      0.13  \n",
       "0               0.75       0.56    0.51      0.54  \n",
       "1               0.74       0.76    0.50      0.60  \n",
       "4               0.72       0.18    0.46      0.26  \n",
       "0               0.70       0.29    0.40      0.34  \n",
       "5               0.67       0.03    0.39      0.06  \n",
       "4               0.63       0.07    0.27      0.11  \n",
       "1               0.61       0.51    0.22      0.30  \n",
       "1               0.61       0.38    0.23      0.29  \n",
       "1               0.60       0.44    0.20      0.28  \n",
       "0               0.59       0.20    0.20      0.20  \n",
       "0               0.51       0.03    0.03      0.03  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(all_scores.sort_values(by='balanced_accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "1\n",
      "2\n",
      "b\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "d = {'a':[1,2], 'b':[3,4]}\n",
    "for key, val in d.items():\n",
    "    print(key)\n",
    "    first, sec = val\n",
    "    print(first)\n",
    "    print(sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9607903993378853\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(pred, y_test)\n",
    "\n",
    "tp, fp, tn, fn = cm[1,1], cm [1,0], cm[0,0], cm[0,1]  # 1's are true\n",
    "tp, fp, tn, fn = cm[0,0], cm [0,1], cm[1,1], cm[1,0]  # 0's are true\n",
    "\n",
    "prec = tp/(tp+fp)\n",
    "print(prec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6e42a3d7400be7cc1f2873a41239adfc85a71a2b7bd4dd5b538442f24ae4903"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
